# æ¨¡å‹è¨“ç·´å·¥ä½œæµç¨‹

ğŸ“ æœ¬æŒ‡å—è©³ç´°èªªæ˜ Make10 å°ˆæ¡ˆä¸­ AI æ¨¡å‹çš„è¨“ç·´å·¥ä½œæµç¨‹ã€è³‡æ–™ç®¡ç†èˆ‡æ¨¡å‹ç”Ÿå‘½é€±æœŸã€‚

## ğŸ”„ è¨“ç·´å·¥ä½œæµç¨‹æ¦‚è¦½

### å®Œæ•´è¨“ç·´ç®¡é“
```
è³‡æ–™æ”¶é›† â†’ è³‡æ–™æ¨™è¨» â†’ é è™•ç† â†’ æ¨¡å‹è¨“ç·´ â†’ é©—è­‰è©•ä¼° â†’ æ¨¡å‹éƒ¨ç½² â†’ ç›£æ§åé¥‹
    â†“           â†“           â†“           â†“           â†“           â†“           â†“
ğŸ“· æ“·å–        ğŸ·ï¸ äººå·¥      ğŸ”§ å¢å¼·      ğŸ§  CNN      ğŸ“Š æ¸¬è©¦      ğŸš€ ä¸Šç·š      ğŸ“ˆ èª¿æ•´
Cell åœ–åƒ      æ¨™è¨»æ•¸å­—     æ­£è¦åŒ–       è¨“ç·´        æº–ç¢ºç‡       æ¨¡å‹        æ•ˆèƒ½
```

## ğŸ“Š è³‡æ–™ç®¡ç†å·¥ä½œæµç¨‹

### 1. è³‡æ–™æ”¶é›†éšæ®µ

#### è‡ªå‹•åŒ–è³‡æ–™æ”¶é›†
```python
def automated_data_collection(num_games=10, cells_per_game=250):
    """è‡ªå‹•åŒ–éŠæˆ²è³‡æ–™æ”¶é›†"""
    
    collected_data = []
    
    for game_idx in range(num_games):
        print(f"æ”¶é›†ç¬¬ {game_idx + 1} å ´éŠæˆ²è³‡æ–™...")
        
        # å•Ÿå‹•éŠæˆ²ä¸¦ç­‰å¾…ç©©å®š
        start_new_game()
        time.sleep(2)
        
        # æ“·å–å®Œæ•´ç›¤é¢
        board_image = capture_game_board()
        
        # åˆ†å‰²æˆå€‹åˆ¥ cell
        cell_images = extract_cell_images(board_image)
        
        # å„²å­˜æ¯å€‹ cell
        for cell_idx, cell_img in enumerate(cell_images):
            filename = f"game_{game_idx:03d}_cell_{cell_idx:03d}.png"
            filepath = save_cell_image(cell_img, filename)
            
            collected_data.append({
                'filename': filename,
                'filepath': filepath,
                'game_id': game_idx,
                'cell_id': cell_idx,
                'timestamp': datetime.now()
            })
    
    # å„²å­˜æ”¶é›†è³‡è¨Š
    save_collection_metadata(collected_data)
    print(f"ç¸½å…±æ”¶é›† {len(collected_data)} å€‹ cell åœ–åƒ")
    
    return collected_data

def extract_cell_images(board_image, grid_size=(5, 5)):
    """å¾ç›¤é¢åœ–åƒä¸­æå–å€‹åˆ¥ cell"""
    
    # æª¢æ¸¬ç¶²æ ¼ç·š
    grid_lines = detect_grid_lines(board_image)
    
    # è¨ˆç®—æ¯å€‹ cell çš„åº§æ¨™
    cell_coordinates = calculate_cell_coordinates(grid_lines, grid_size)
    
    cell_images = []
    for i, (x, y, w, h) in enumerate(cell_coordinates):
        # æå– cell å€åŸŸ
        cell = board_image[y:y+h, x:x+w]
        
        # èª¿æ•´å¤§å°åˆ°æ¨™æº–å°ºå¯¸
        cell_resized = cv2.resize(cell, (45, 45))
        
        cell_images.append(cell_resized)
    
    return cell_images
```

### 2. è³‡æ–™æ¨™è¨»éšæ®µ

#### äº’å‹•å¼æ¨™è¨»å·¥å…·
```python
class InteractiveLabelingTool:
    """äº’å‹•å¼è³‡æ–™æ¨™è¨»å·¥å…·"""
    
    def __init__(self, data_directory="data/training/images"):
        self.data_dir = Path(data_directory)
        self.labels_file = Path("data/training/labels.csv")
        self.current_labels = self.load_existing_labels()
        
    def start_labeling_session(self):
        """é–‹å§‹æ¨™è¨»æœƒè©±"""
        
        unlabeled_images = self.get_unlabeled_images()
        print(f"æ‰¾åˆ° {len(unlabeled_images)} å€‹æœªæ¨™è¨»çš„åœ–åƒ")
        
        for img_path in unlabeled_images:
            try:
                label = self.label_single_image(img_path)
                if label is not None:
                    self.save_label(img_path, label)
                    
            except KeyboardInterrupt:
                print("\næ¨™è¨»æœƒè©±è¢«ä½¿ç”¨è€…ä¸­æ–·")
                break
            except Exception as e:
                print(f"æ¨™è¨»åœ–åƒ {img_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        print("æ¨™è¨»æœƒè©±å®Œæˆ")
    
    def label_single_image(self, img_path):
        """æ¨™è¨»å–®ä¸€åœ–åƒ"""
        
        # è¼‰å…¥ä¸¦é¡¯ç¤ºåœ–åƒ
        image = cv2.imread(str(img_path))
        if image is None:
            print(f"ç„¡æ³•è¼‰å…¥åœ–åƒ: {img_path}")
            return None
        
        # æ”¾å¤§é¡¯ç¤ºä»¥ä¾¿è­˜åˆ¥
        display_image = cv2.resize(image, (200, 200), interpolation=cv2.INTER_NEAREST)
        
        cv2.imshow(f"æ¨™è¨»: {img_path.name}", display_image)
        cv2.moveWindow(f"æ¨™è¨»: {img_path.name}", 100, 100)
        
        print(f"\næ¨™è¨»åœ–åƒ: {img_path.name}")
        print("è«‹è¼¸å…¥æ•¸å­— (0-9), æˆ–æŒ‰ 's' è·³é, 'q' é€€å‡º:")
        
        while True:
            key = cv2.waitKey(0) & 0xFF
            
            # æ•¸å­—éµ (0-9)
            if ord('0') <= key <= ord('9'):
                label = key - ord('0')
                cv2.destroyAllWindows()
                return label
            
            # è·³é
            elif key == ord('s'):
                print("è·³éæ­¤åœ–åƒ")
                cv2.destroyAllWindows()
                return None
            
            # é€€å‡º
            elif key == ord('q'):
                cv2.destroyAllWindows()
                raise KeyboardInterrupt()
            
            # ç„¡æ•ˆè¼¸å…¥
            else:
                print("ç„¡æ•ˆè¼¸å…¥ï¼Œè«‹è¼¸å…¥ 0-9 æˆ– 's'/'q'")
    
    def get_unlabeled_images(self):
        """å–å¾—æœªæ¨™è¨»çš„åœ–åƒåˆ—è¡¨"""
        
        all_images = list(self.data_dir.glob("*.png"))
        labeled_images = set(self.current_labels.keys())
        
        unlabeled = [img for img in all_images 
                    if img.name not in labeled_images]
        
        return sorted(unlabeled)
    
    def save_label(self, img_path, label):
        """å„²å­˜æ¨™ç±¤"""
        
        self.current_labels[img_path.name] = label
        
        # æ›´æ–° CSV æª”æ¡ˆ
        with open(self.labels_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['filename', 'label'])
            
            for filename, label in self.current_labels.items():
                writer.writerow([filename, label])
        
        print(f"å·²å„²å­˜: {img_path.name} â†’ {label}")
    
    def load_existing_labels(self):
        """è¼‰å…¥ç¾æœ‰æ¨™ç±¤"""
        
        labels = {}
        
        if self.labels_file.exists():
            with open(self.labels_file, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    labels[row['filename']] = int(row['label'])
        
        return labels
```

#### æ¨™è¨»å“è³ªæ§åˆ¶
```python
class LabelQualityController:
    """æ¨™è¨»å“è³ªæ§åˆ¶å™¨"""
    
    def __init__(self, labels_file="data/training/labels.csv"):
        self.labels_file = Path(labels_file)
        self.labels_df = pd.read_csv(labels_file)
    
    def analyze_label_distribution(self):
        """åˆ†ææ¨™ç±¤åˆ†ä½ˆ"""
        
        distribution = self.labels_df['label'].value_counts().sort_index()
        
        print("=== æ¨™ç±¤åˆ†ä½ˆåˆ†æ ===")
        for label, count in distribution.items():
            percentage = count / len(self.labels_df) * 100
            print(f"æ•¸å­— {label}: {count} å€‹æ¨£æœ¬ ({percentage:.1f}%)")
        
        # æª¢æŸ¥è³‡æ–™å¹³è¡¡æ€§
        min_count = distribution.min()
        max_count = distribution.max()
        imbalance_ratio = max_count / min_count
        
        if imbalance_ratio > 3:
            print(f"\nâš ï¸  è³‡æ–™ä¸å¹³è¡¡è­¦å‘Š: æœ€å¤§/æœ€å°æ¯”ä¾‹ = {imbalance_ratio:.1f}")
            print("å»ºè­°å¢åŠ æ¨£æœ¬æ•¸é‡è¼ƒå°‘çš„é¡åˆ¥")
        
        return distribution
    
    def find_duplicate_labels(self):
        """å°‹æ‰¾é‡è¤‡æ¨™ç±¤"""
        
        # è¼‰å…¥åœ–åƒä¸¦è¨ˆç®—é›œæ¹Š
        image_hashes = {}
        duplicates = []
        
        for _, row in self.labels_df.iterrows():
            img_path = Path("data/training/images") / row['filename']
            
            if img_path.exists():
                image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                img_hash = hashlib.md5(image.tobytes()).hexdigest()
                
                if img_hash in image_hashes:
                    duplicates.append({
                        'hash': img_hash,
                        'files': [image_hashes[img_hash], row['filename']],
                        'labels': [self.get_label_for_file(image_hashes[img_hash]), row['label']]
                    })
                else:
                    image_hashes[img_hash] = row['filename']
        
        if duplicates:
            print(f"ç™¼ç¾ {len(duplicates)} çµ„é‡è¤‡åœ–åƒ")
            for dup in duplicates:
                print(f"æª”æ¡ˆ: {dup['files']}, æ¨™ç±¤: {dup['labels']}")
        
        return duplicates
    
    def validate_labels_with_model(self, model_path="data/models/model.keras"):
        """ä½¿ç”¨ç¾æœ‰æ¨¡å‹é©—è­‰æ¨™ç±¤"""
        
        if not Path(model_path).exists():
            print("æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³éé©—è­‰")
            return
        
        model = tf.keras.models.load_model(model_path)
        inconsistencies = []
        
        for _, row in self.labels_df.iterrows():
            img_path = Path("data/training/images") / row['filename']
            
            if img_path.exists():
                # è¼‰å…¥ä¸¦é è™•ç†åœ–åƒ
                image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                processed = preprocess_for_prediction(image)
                
                # æ¨¡å‹é æ¸¬
                prediction = model.predict(processed, verbose=0)
                predicted_class = np.argmax(prediction)
                confidence = np.max(prediction)
                
                # æª¢æŸ¥ä¸ä¸€è‡´æ€§
                if predicted_class != row['label'] and confidence > 0.8:
                    inconsistencies.append({
                        'filename': row['filename'],
                        'human_label': row['label'],
                        'model_prediction': predicted_class,
                        'confidence': confidence
                    })
        
        if inconsistencies:
            print(f"ç™¼ç¾ {len(inconsistencies)} å€‹å¯èƒ½çš„æ¨™è¨»éŒ¯èª¤")
            for inc in inconsistencies[:10]:  # åªé¡¯ç¤ºå‰ 10 å€‹
                print(f"{inc['filename']}: äººå·¥={inc['human_label']}, "
                      f"æ¨¡å‹={inc['model_prediction']} (ä¿¡å¿ƒåº¦={inc['confidence']:.3f})")
        
        return inconsistencies
```

### 3. è³‡æ–™é è™•ç†éšæ®µ

#### é€²éšè³‡æ–™å¢å¼·
```python
class AdvancedDataAugmentation:
    """é€²éšè³‡æ–™å¢å¼·å™¨"""
    
    def __init__(self, augmentation_factor=3):
        self.aug_factor = augmentation_factor
        
    def augment_dataset(self, images, labels):
        """å°æ•´å€‹è³‡æ–™é›†é€²è¡Œå¢å¼·"""
        
        augmented_images = []
        augmented_labels = []
        
        for img, label in zip(images, labels):
            # åŸå§‹åœ–åƒ
            augmented_images.append(img)
            augmented_labels.append(label)
            
            # ç”Ÿæˆå¢å¼·è®Šé«”
            for _ in range(self.aug_factor):
                aug_img = self.apply_random_augmentation(img)
                augmented_images.append(aug_img)
                augmented_labels.append(label)
        
        return np.array(augmented_images), np.array(augmented_labels)
    
    def apply_random_augmentation(self, image):
        """éš¨æ©Ÿæ‡‰ç”¨å¢å¼·æŠ€è¡“"""
        
        aug_image = image.copy()
        
        # éš¨æ©Ÿé¸æ“‡å¢å¼·æŠ€è¡“
        augmentations = [
            self.rotate_image,
            self.scale_image,
            self.translate_image,
            self.add_noise,
            self.adjust_brightness,
            self.adjust_contrast
        ]
        
        # éš¨æ©Ÿé¸æ“‡ 1-3 ç¨®å¢å¼·æŠ€è¡“
        num_augs = random.randint(1, 3)
        selected_augs = random.sample(augmentations, num_augs)
        
        for aug_func in selected_augs:
            aug_image = aug_func(aug_image)
        
        return aug_image
    
    def rotate_image(self, image, max_angle=15):
        """æ—‹è½‰åœ–åƒ"""
        angle = random.uniform(-max_angle, max_angle)
        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(image, rotation_matrix, (width, height))
        
        return rotated
    
    def scale_image(self, image, scale_range=(0.8, 1.2)):
        """ç¸®æ”¾åœ–åƒ"""
        scale = random.uniform(*scale_range)
        height, width = image.shape[:2]
        
        new_height, new_width = int(height * scale), int(width * scale)
        scaled = cv2.resize(image, (new_width, new_height))
        
        # è£å‰ªæˆ–å¡«å……åˆ°åŸå§‹å¤§å°
        if scale > 1.0:
            # ç¸®æ”¾å¾Œè¼ƒå¤§ï¼Œéœ€è¦è£å‰ª
            start_y = (new_height - height) // 2
            start_x = (new_width - width) // 2
            scaled = scaled[start_y:start_y+height, start_x:start_x+width]
        else:
            # ç¸®æ”¾å¾Œè¼ƒå°ï¼Œéœ€è¦å¡«å……
            padded = np.zeros_like(image)
            start_y = (height - new_height) // 2
            start_x = (width - new_width) // 2
            padded[start_y:start_y+new_height, start_x:start_x+new_width] = scaled
            scaled = padded
        
        return scaled
    
    def add_noise(self, image, noise_factor=0.1):
        """æ·»åŠ é«˜æ–¯é›œè¨Š"""
        noise = np.random.normal(0, noise_factor * 255, image.shape)
        noisy = image.astype(np.float32) + noise
        noisy = np.clip(noisy, 0, 255).astype(np.uint8)
        
        return noisy
```

## ğŸ§  æ¨¡å‹è¨“ç·´éšæ®µ

### é€²éšè¨“ç·´ç®¡é“
```python
class AdvancedTrainingPipeline:
    """é€²éšè¨“ç·´ç®¡é“"""
    
    def __init__(self, config):
        self.config = config
        self.model = None
        self.history = None
        
    def train_with_cross_validation(self, X, y, k_folds=5):
        """ä½¿ç”¨äº¤å‰é©—è­‰è¨“ç·´"""
        
        from sklearn.model_selection import StratifiedKFold
        
        kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
        cv_scores = []
        best_model = None
        best_score = 0
        
        for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y.argmax(axis=1))):
            print(f"\n=== è¨“ç·´ç¬¬ {fold + 1} æŠ˜ ===")
            
            # åˆ†å‰²è³‡æ–™
            X_train_fold, X_val_fold = X[train_idx], X[val_idx]
            y_train_fold, y_val_fold = y[train_idx], y[val_idx]
            
            # å»ºç«‹æ–°æ¨¡å‹
            model = self.create_model()
            
            # è¨“ç·´æ¨¡å‹
            history = model.fit(
                X_train_fold, y_train_fold,
                validation_data=(X_val_fold, y_val_fold),
                epochs=self.config['epochs'],
                batch_size=self.config['batch_size'],
                callbacks=self.create_callbacks(fold),
                verbose=1
            )
            
            # è©•ä¼°æ¨¡å‹
            val_score = model.evaluate(X_val_fold, y_val_fold, verbose=0)[1]
            cv_scores.append(val_score)
            
            print(f"ç¬¬ {fold + 1} æŠ˜é©—è­‰æº–ç¢ºç‡: {val_score:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_score > best_score:
                best_score = val_score
                best_model = model
        
        print(f"\näº¤å‰é©—è­‰çµæœ:")
        print(f"å¹³å‡æº–ç¢ºç‡: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}")
        print(f"æœ€ä½³æº–ç¢ºç‡: {best_score:.4f}")
        
        return best_model, cv_scores
    
    def train_with_early_stopping(self, X_train, y_train, X_val, y_val):
        """ä½¿ç”¨æ—©åœæ©Ÿåˆ¶è¨“ç·´"""
        
        model = self.create_model()
        
        # æ—©åœå›èª¿
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True,
            verbose=1
        )
        
        # å­¸ç¿’ç‡è¡°æ¸›
        lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        )
        
        # æ¨¡å‹æª¢æŸ¥é»
        checkpoint = tf.keras.callbacks.ModelCheckpoint(
            filepath='checkpoints/best_model_epoch_{epoch:02d}.keras',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
        
        # è¨“ç·´æ¨¡å‹
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=self.config['max_epochs'],
            batch_size=self.config['batch_size'],
            callbacks=[early_stopping, lr_scheduler, checkpoint],
            verbose=1
        )
        
        return model, history
    
    def hyperparameter_tuning(self, X_train, y_train, X_val, y_val):
        """è¶…åƒæ•¸èª¿æ•´"""
        
        import itertools
        
        # å®šç¾©è¶…åƒæ•¸æœå°‹ç©ºé–“
        param_grid = {
            'learning_rate': [0.001, 0.0005, 0.0001],
            'batch_size': [16, 32, 64],
            'dropout_rate': [0.3, 0.5, 0.7],
            'num_filters': [16, 32, 64]
        }
        
        best_params = None
        best_score = 0
        results = []
        
        # ç¶²æ ¼æœå°‹
        param_combinations = list(itertools.product(*param_grid.values()))
        
        for i, params in enumerate(param_combinations):
            param_dict = dict(zip(param_grid.keys(), params))
            print(f"\n=== æ¸¬è©¦åƒæ•¸çµ„åˆ {i+1}/{len(param_combinations)} ===")
            print(f"åƒæ•¸: {param_dict}")
            
            try:
                # ä½¿ç”¨ç•¶å‰åƒæ•¸å»ºç«‹å’Œè¨“ç·´æ¨¡å‹
                model = self.create_model_with_params(param_dict)
                
                history = model.fit(
                    X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=20,  # è¼ƒå°‘çš„ epochs ç”¨æ–¼å¿«é€Ÿè©•ä¼°
                    batch_size=param_dict['batch_size'],
                    verbose=0
                )
                
                # è©•ä¼°æ¨¡å‹
                val_score = max(history.history['val_accuracy'])
                
                results.append({
                    'params': param_dict,
                    'score': val_score
                })
                
                print(f"é©—è­‰æº–ç¢ºç‡: {val_score:.4f}")
                
                if val_score > best_score:
                    best_score = val_score
                    best_params = param_dict
                    
            except Exception as e:
                print(f"åƒæ•¸çµ„åˆå¤±æ•—: {e}")
                continue
        
        print(f"\n=== è¶…åƒæ•¸èª¿æ•´çµæœ ===")
        print(f"æœ€ä½³åƒæ•¸: {best_params}")
        print(f"æœ€ä½³åˆ†æ•¸: {best_score:.4f}")
        
        return best_params, results
```

### æ¨¡å‹è¨“ç·´ç›£æ§
```python
class TrainingMonitor:
    """è¨“ç·´éç¨‹ç›£æ§å™¨"""
    
    def __init__(self, log_dir="logs/training"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
    def create_tensorboard_callback(self, experiment_name):
        """å»ºç«‹ TensorBoard å›èª¿"""
        
        log_path = self.log_dir / experiment_name
        
        return tf.keras.callbacks.TensorBoard(
            log_dir=str(log_path),
            histogram_freq=1,
            write_graph=True,
            write_images=True,
            update_freq='epoch'
        )
    
    def create_custom_logging_callback(self):
        """å»ºç«‹è‡ªå®šç¾©æ—¥èªŒå›èª¿"""
        
        class CustomLoggingCallback(tf.keras.callbacks.Callback):
            def __init__(self, monitor):
                super().__init__()
                self.monitor = monitor
                
            def on_epoch_end(self, epoch, logs=None):
                # è¨˜éŒ„è©³ç´°çš„è¨“ç·´è³‡è¨Š
                self.monitor.log_epoch_metrics(epoch, logs)
                
                # æª¢æŸ¥ç•°å¸¸æƒ…æ³
                if logs.get('loss', 0) > 10:
                    print("è­¦å‘Š: æå¤±å€¼éé«˜ï¼Œå¯èƒ½å­˜åœ¨æ¢¯åº¦çˆ†ç‚¸")
                
                if logs.get('val_accuracy', 0) < 0.1:
                    print("è­¦å‘Š: é©—è­‰æº–ç¢ºç‡éä½ï¼Œæª¢æŸ¥è³‡æ–™æˆ–æ¨¡å‹")
        
        return CustomLoggingCallback(self)
    
    def log_epoch_metrics(self, epoch, logs):
        """è¨˜éŒ„æ¯å€‹ epoch çš„æŒ‡æ¨™"""
        
        timestamp = datetime.now().isoformat()
        log_entry = {
            'timestamp': timestamp,
            'epoch': epoch,
            'metrics': logs
        }
        
        # å„²å­˜åˆ° JSON æ—¥èªŒ
        log_file = self.log_dir / "training_log.jsonl"
        with open(log_file, 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
    
    def plot_training_history(self, history, save_path=None):
        """ç¹ªè£½è¨“ç·´æ­·å²"""
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # æº–ç¢ºç‡
        axes[0, 0].plot(history.history['accuracy'], label='Training')
        axes[0, 0].plot(history.history['val_accuracy'], label='Validation')
        axes[0, 0].set_title('Model Accuracy')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        
        # æå¤±
        axes[0, 1].plot(history.history['loss'], label='Training')
        axes[0, 1].plot(history.history['val_loss'], label='Validation')
        axes[0, 1].set_title('Model Loss')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        
        # å­¸ç¿’ç‡ (å¦‚æœæœ‰è¨˜éŒ„)
        if 'lr' in history.history:
            axes[1, 0].plot(history.history['lr'])
            axes[1, 0].set_title('Learning Rate')
            axes[1, 0].set_xlabel('Epoch')
            axes[1, 0].set_ylabel('LR')
        
        # æ¢¯åº¦ç¯„æ•¸ (å¦‚æœæœ‰è¨˜éŒ„)
        if 'gradient_norm' in history.history:
            axes[1, 1].plot(history.history['gradient_norm'])
            axes[1, 1].set_title('Gradient Norm')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Norm')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
```

## ğŸš€ æ¨¡å‹éƒ¨ç½²èˆ‡ç›£æ§

### è‡ªå‹•åŒ–éƒ¨ç½²ç®¡é“
```python
class ModelDeploymentPipeline:
    """æ¨¡å‹éƒ¨ç½²ç®¡é“"""
    
    def __init__(self):
        self.deployment_config = {
            'min_accuracy': 0.85,
            'max_model_size': 50 * 1024 * 1024,  # 50MB
            'max_inference_time': 100  # ms
        }
    
    def deploy_model(self, model_path, test_data):
        """éƒ¨ç½²æ¨¡å‹åˆ°ç”Ÿç”¢ç’°å¢ƒ"""
        
        # 1. è¼‰å…¥æ¨¡å‹
        model = tf.keras.models.load_model(model_path)
        
        # 2. æ¨¡å‹é©—è­‰
        validation_result = self.validate_model(model, test_data)
        
        if not validation_result['passed']:
            raise ValueError(f"æ¨¡å‹é©—è­‰å¤±æ•—: {validation_result['errors']}")
        
        # 3. æ¨¡å‹æœ€ä½³åŒ–
        optimized_model_path = self.optimize_model(model)
        
        # 4. A/B æ¸¬è©¦æº–å‚™
        ab_test_config = self.prepare_ab_test(optimized_model_path)
        
        # 5. é€æ­¥éƒ¨ç½²
        deployment_result = self.gradual_rollout(optimized_model_path, ab_test_config)
        
        return deployment_result
    
    def validate_model(self, model, test_data):
        """é©—è­‰æ¨¡å‹æ˜¯å¦ç¬¦åˆéƒ¨ç½²æ¨™æº–"""
        
        X_test, y_test = test_data
        errors = []
        
        # æº–ç¢ºç‡æª¢æŸ¥
        test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
        if test_accuracy < self.deployment_config['min_accuracy']:
            errors.append(f"æº–ç¢ºç‡ä¸è¶³: {test_accuracy:.3f} < {self.deployment_config['min_accuracy']}")
        
        # æ¨¡å‹å¤§å°æª¢æŸ¥
        model_size = self.get_model_size(model)
        if model_size > self.deployment_config['max_model_size']:
            errors.append(f"æ¨¡å‹éå¤§: {model_size} bytes")
        
        # æ¨ç†æ™‚é–“æª¢æŸ¥
        inference_time = self.measure_inference_time(model, X_test[:10])
        if inference_time > self.deployment_config['max_inference_time']:
            errors.append(f"æ¨ç†æ™‚é–“éé•·: {inference_time:.1f}ms")
        
        return {
            'passed': len(errors) == 0,
            'errors': errors,
            'metrics': {
                'accuracy': test_accuracy,
                'model_size': model_size,
                'inference_time': inference_time
            }
        }
    
    def gradual_rollout(self, model_path, ab_test_config):
        """é€æ­¥éƒ¨ç½²æ–°æ¨¡å‹"""
        
        rollout_stages = [0.05, 0.1, 0.25, 0.5, 1.0]  # 5%, 10%, 25%, 50%, 100%
        
        for stage_percent in rollout_stages:
            print(f"éƒ¨ç½²éšæ®µ: {stage_percent*100:.0f}% ä½¿ç”¨è€…")
            
            # æ›´æ–° A/B æ¸¬è©¦æ¯”ä¾‹
            self.update_ab_test_ratio(ab_test_config, stage_percent)
            
            # ç›£æ§ä¸€æ®µæ™‚é–“
            time.sleep(300)  # ç­‰å¾… 5 åˆ†é˜
            
            # æª¢æŸ¥é—œéµæŒ‡æ¨™
            metrics = self.collect_deployment_metrics()
            
            if not self.check_deployment_health(metrics):
                print("éƒ¨ç½²å¥åº·æª¢æŸ¥å¤±æ•—ï¼ŒåŸ·è¡Œå›æ»¾")
                self.rollback_deployment()
                return {'status': 'failed', 'stage': stage_percent}
            
            print(f"éšæ®µ {stage_percent*100:.0f}% éƒ¨ç½²æˆåŠŸ")
        
        return {'status': 'success', 'deployed_at': datetime.now()}
```

### ç”Ÿç”¢ç’°å¢ƒç›£æ§
```python
class ProductionMonitor:
    """ç”Ÿç”¢ç’°å¢ƒæ¨¡å‹ç›£æ§"""
    
    def __init__(self):
        self.metrics_buffer = []
        self.alert_thresholds = {
            'accuracy_drop': 0.05,
            'inference_time_spike': 2.0,
            'error_rate_spike': 0.1
        }
    
    def monitor_model_performance(self):
        """ç›£æ§æ¨¡å‹åœ¨ç”Ÿç”¢ç’°å¢ƒçš„è¡¨ç¾"""
        
        while True:
            try:
                # æ”¶é›†æœ€è¿‘çš„é æ¸¬çµæœ
                recent_predictions = self.get_recent_predictions()
                
                # è¨ˆç®—é—œéµæŒ‡æ¨™
                metrics = self.calculate_metrics(recent_predictions)
                
                # æª¢æŸ¥æ˜¯å¦éœ€è¦è­¦å ±
                alerts = self.check_for_alerts(metrics)
                
                if alerts:
                    self.send_alerts(alerts)
                
                # è¨˜éŒ„æŒ‡æ¨™
                self.log_metrics(metrics)
                
                time.sleep(60)  # æ¯åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ç›£æ§éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
                time.sleep(60)
    
    def calculate_metrics(self, predictions):
        """è¨ˆç®—é—œéµæŒ‡æ¨™"""
        
        if not predictions:
            return {}
        
        metrics = {
            'timestamp': datetime.now(),
            'total_predictions': len(predictions),
            'avg_confidence': np.mean([p['confidence'] for p in predictions]),
            'low_confidence_rate': len([p for p in predictions if p['confidence'] < 0.8]) / len(predictions),
            'avg_inference_time': np.mean([p['inference_time'] for p in predictions]),
            'error_rate': len([p for p in predictions if p.get('error')]) / len(predictions)
        }
        
        return metrics
    
    def check_for_alerts(self, current_metrics):
        """æª¢æŸ¥æ˜¯å¦éœ€è¦ç™¼é€è­¦å ±"""
        
        alerts = []
        
        # æ¯”è¼ƒæ­·å²æŒ‡æ¨™
        if len(self.metrics_buffer) > 0:
            baseline = self.calculate_baseline_metrics()
            
            # æº–ç¢ºç‡ä¸‹é™æª¢æŸ¥
            if current_metrics.get('avg_confidence', 0) < baseline.get('avg_confidence', 1) - self.alert_thresholds['accuracy_drop']:
                alerts.append({
                    'type': 'accuracy_drop',
                    'message': f"æ¨¡å‹ä¿¡å¿ƒåº¦ä¸‹é™: {current_metrics['avg_confidence']:.3f} vs {baseline['avg_confidence']:.3f}",
                    'severity': 'high'
                })
            
            # æ¨ç†æ™‚é–“æ¿€å¢æª¢æŸ¥
            if current_metrics.get('avg_inference_time', 0) > baseline.get('avg_inference_time', 0) * self.alert_thresholds['inference_time_spike']:
                alerts.append({
                    'type': 'inference_time_spike',
                    'message': f"æ¨ç†æ™‚é–“æ¿€å¢: {current_metrics['avg_inference_time']:.1f}ms vs {baseline['avg_inference_time']:.1f}ms",
                    'severity': 'medium'
                })
            
            # éŒ¯èª¤ç‡æ¿€å¢æª¢æŸ¥
            if current_metrics.get('error_rate', 0) > self.alert_thresholds['error_rate_spike']:
                alerts.append({
                    'type': 'error_rate_spike',
                    'message': f"éŒ¯èª¤ç‡éé«˜: {current_metrics['error_rate']:.3f}",
                    'severity': 'high'
                })
        
        return alerts
```

é€éé€™å€‹å®Œæ•´çš„è¨“ç·´å·¥ä½œæµç¨‹ï¼ŒMake10 å°ˆæ¡ˆèƒ½å¤ ç³»çµ±åŒ–åœ°ç®¡ç† AI æ¨¡å‹çš„æ•´å€‹ç”Ÿå‘½é€±æœŸï¼Œå¾è³‡æ–™æ”¶é›†åˆ°ç”Ÿç”¢éƒ¨ç½²ï¼Œç¢ºä¿æ¨¡å‹å“è³ªå’Œç³»çµ±ç©©å®šæ€§ã€‚
