# ResNet50 æ¨¡å‹è¨“ç·´å·¥ä½œæµç¨‹

ğŸ“ æœ¬æŒ‡å—è©³ç´°èªªæ˜ Make10 å°ˆæ¡ˆä¸­åŸºæ–¼ ResNet50 çš„ AI æ¨¡å‹è¨“ç·´å·¥ä½œæµç¨‹ã€è³‡æ–™ç®¡ç†èˆ‡æ¨¡å‹ç”Ÿå‘½é€±æœŸã€‚

## ğŸ”„ ResNet50 è¨“ç·´å·¥ä½œæµç¨‹æ¦‚è¦½

### å®Œæ•´è¨“ç·´ç®¡é“
```
è³‡æ–™æ”¶é›† â†’ è³‡æ–™æ¨™è¨» â†’ é è™•ç† â†’ é·ç§»å­¸ç¿’ â†’ å¾®èª¿è¨“ç·´ â†’ é©—è­‰è©•ä¼° â†’ æ¨¡å‹éƒ¨ç½² â†’ ç›£æ§åé¥‹
    â†“           â†“           â†“           â†“           â†“           â†“           â†“           â†“
ğŸ“· æ“·å–        ğŸ·ï¸ äººå·¥      ğŸ”§ RGB      ğŸ§  ImageNet  ğŸ¯ Fine     ğŸ“Š æ¸¬è©¦      ğŸš€ ä¸Šç·š      ğŸ“ˆ èª¿æ•´
Cell åœ–åƒ      æ¨™è¨»æ•¸å­—     224x224     é è¨“ç·´      Tuning      æº–ç¢ºç‡       æ¨¡å‹        æ•ˆèƒ½
```

## ğŸ“Š ResNet50 å°ˆç”¨è³‡æ–™ç®¡ç†

### 1. è³‡æ–™æ”¶é›†éšæ®µ (é‡å° ResNet50 å„ªåŒ–)

#### é«˜è§£æåº¦è³‡æ–™æ”¶é›†
```python
def collect_high_resolution_data(num_games=10, target_size=(224, 224)):
    """ç‚º ResNet50 æ”¶é›†é«˜è§£æåº¦è³‡æ–™"""
    
    collected_data = []
    
    for game_idx in range(num_games):
        print(f"æ”¶é›†ç¬¬ {game_idx + 1} å ´éŠæˆ²é«˜è§£æåº¦è³‡æ–™...")
        
        # å•Ÿå‹•éŠæˆ²ä¸¦ç­‰å¾…ç©©å®š
        start_new_game()
        time.sleep(2)
        
        # æ“·å–å®Œæ•´ç›¤é¢ (é«˜è§£æåº¦)
        board_image = capture_game_board(scale_factor=2.0)  # 2å€è§£æåº¦
        
        # åˆ†å‰²æˆå€‹åˆ¥ cell ä¸¦ä¿æŒé«˜è§£æåº¦
        cell_images = extract_cell_images_hd(board_image, target_size)
        
        # å„²å­˜æ¯å€‹ cell (ä¿å­˜ç‚º RGB æ ¼å¼)
        for cell_idx, cell_img in enumerate(cell_images):
            # ç¢ºä¿ RGB æ ¼å¼
            if len(cell_img.shape) == 2:
                cell_img = cv2.cvtColor(cell_img, cv2.COLOR_GRAY2RGB)
            elif cell_img.shape[2] == 4:
                cell_img = cv2.cvtColor(cell_img, cv2.COLOR_BGRA2RGB)
            
            filename = f"resnet_game_{game_idx:03d}_cell_{cell_idx:03d}.png"
            filepath = save_cell_image_rgb(cell_img, filename)
            
            collected_data.append({
                'filename': filename,
                'filepath': filepath,
                'game_id': game_idx,
                'cell_id': cell_idx,
                'resolution': cell_img.shape,
                'timestamp': datetime.now()
            })
    
    # å„²å­˜æ”¶é›†è³‡è¨Š
    save_collection_metadata(collected_data)
    print(f"ç¸½å…±æ”¶é›† {len(collected_data)} å€‹ cell åœ–åƒ")
    
    return collected_data

def extract_cell_images(board_image, grid_size=(5, 5)):
    """å¾ç›¤é¢åœ–åƒä¸­æå–å€‹åˆ¥ cell"""
    
    # æª¢æ¸¬ç¶²æ ¼ç·š
    grid_lines = detect_grid_lines(board_image)
    
    # è¨ˆç®—æ¯å€‹ cell çš„åº§æ¨™
    cell_coordinates = calculate_cell_coordinates(grid_lines, grid_size)
    
    cell_images = []
    for i, (x, y, w, h) in enumerate(cell_coordinates):
        # æå– cell å€åŸŸ
        cell = board_image[y:y+h, x:x+w]
        
        # èª¿æ•´å¤§å°åˆ°æ¨™æº–å°ºå¯¸
        cell_resized = cv2.resize(cell, (45, 45))
        
        cell_images.append(cell_resized)
    
    return cell_images
```

### 2. è³‡æ–™æ¨™è¨»éšæ®µ

#### äº’å‹•å¼æ¨™è¨»å·¥å…·
```python
class InteractiveLabelingTool:
    """äº’å‹•å¼è³‡æ–™æ¨™è¨»å·¥å…·"""
    
    def __init__(self, data_directory="data/training/images"):
        self.data_dir = Path(data_directory)
        self.labels_file = Path("data/training/labels.csv")
        self.current_labels = self.load_existing_labels()
        
    def start_labeling_session(self):
        """é–‹å§‹æ¨™è¨»æœƒè©±"""
        
        unlabeled_images = self.get_unlabeled_images()
        print(f"æ‰¾åˆ° {len(unlabeled_images)} å€‹æœªæ¨™è¨»çš„åœ–åƒ")
        
        for img_path in unlabeled_images:
            try:
                label = self.label_single_image(img_path)
                if label is not None:
                    self.save_label(img_path, label)
                    
            except KeyboardInterrupt:
                print("\næ¨™è¨»æœƒè©±è¢«ä½¿ç”¨è€…ä¸­æ–·")
                break
            except Exception as e:
                print(f"æ¨™è¨»åœ–åƒ {img_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        print("æ¨™è¨»æœƒè©±å®Œæˆ")
    
    def label_single_image(self, img_path):
        """æ¨™è¨»å–®ä¸€åœ–åƒ"""
        
        # è¼‰å…¥ä¸¦é¡¯ç¤ºåœ–åƒ
        image = cv2.imread(str(img_path))
        if image is None:
            print(f"ç„¡æ³•è¼‰å…¥åœ–åƒ: {img_path}")
            return None
        
        # æ”¾å¤§é¡¯ç¤ºä»¥ä¾¿è­˜åˆ¥
        display_image = cv2.resize(image, (200, 200), interpolation=cv2.INTER_NEAREST)
        
        cv2.imshow(f"æ¨™è¨»: {img_path.name}", display_image)
        cv2.moveWindow(f"æ¨™è¨»: {img_path.name}", 100, 100)
        
        print(f"\næ¨™è¨»åœ–åƒ: {img_path.name}")
        print("è«‹è¼¸å…¥æ•¸å­— (0-9), æˆ–æŒ‰ 's' è·³é, 'q' é€€å‡º:")
        
        while True:
            key = cv2.waitKey(0) & 0xFF
            
            # æ•¸å­—éµ (0-9)
            if ord('0') <= key <= ord('9'):
                label = key - ord('0')
                cv2.destroyAllWindows()
                return label
            
            # è·³é
            elif key == ord('s'):
                print("è·³éæ­¤åœ–åƒ")
                cv2.destroyAllWindows()
                return None
            
            # é€€å‡º
            elif key == ord('q'):
                cv2.destroyAllWindows()
                raise KeyboardInterrupt()
            
            # ç„¡æ•ˆè¼¸å…¥
            else:
                print("ç„¡æ•ˆè¼¸å…¥ï¼Œè«‹è¼¸å…¥ 0-9 æˆ– 's'/'q'")
    
    def get_unlabeled_images(self):
        """å–å¾—æœªæ¨™è¨»çš„åœ–åƒåˆ—è¡¨"""
        
        all_images = list(self.data_dir.glob("*.png"))
        labeled_images = set(self.current_labels.keys())
        
        unlabeled = [img for img in all_images 
                    if img.name not in labeled_images]
        
        return sorted(unlabeled)
    
    def save_label(self, img_path, label):
        """å„²å­˜æ¨™ç±¤"""
        
        self.current_labels[img_path.name] = label
        
        # æ›´æ–° CSV æª”æ¡ˆ
        with open(self.labels_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(['filename', 'label'])
            
            for filename, label in self.current_labels.items():
                writer.writerow([filename, label])
        
        print(f"å·²å„²å­˜: {img_path.name} â†’ {label}")
    
    def load_existing_labels(self):
        """è¼‰å…¥ç¾æœ‰æ¨™ç±¤"""
        
        labels = {}
        
        if self.labels_file.exists():
            with open(self.labels_file, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    labels[row['filename']] = int(row['label'])
        
        return labels
```

#### æ¨™è¨»å“è³ªæ§åˆ¶
```python
class LabelQualityController:
    """æ¨™è¨»å“è³ªæ§åˆ¶å™¨"""
    
    def __init__(self, labels_file="data/training/labels.csv"):
        self.labels_file = Path(labels_file)
        self.labels_df = pd.read_csv(labels_file)
    
    def analyze_label_distribution(self):
        """åˆ†ææ¨™ç±¤åˆ†ä½ˆ"""
        
        distribution = self.labels_df['label'].value_counts().sort_index()
        
        print("=== æ¨™ç±¤åˆ†ä½ˆåˆ†æ ===")
        for label, count in distribution.items():
            percentage = count / len(self.labels_df) * 100
            print(f"æ•¸å­— {label}: {count} å€‹æ¨£æœ¬ ({percentage:.1f}%)")
        
        # æª¢æŸ¥è³‡æ–™å¹³è¡¡æ€§
        min_count = distribution.min()
        max_count = distribution.max()
        imbalance_ratio = max_count / min_count
        
        if imbalance_ratio > 3:
            print(f"\nâš ï¸  è³‡æ–™ä¸å¹³è¡¡è­¦å‘Š: æœ€å¤§/æœ€å°æ¯”ä¾‹ = {imbalance_ratio:.1f}")
            print("å»ºè­°å¢åŠ æ¨£æœ¬æ•¸é‡è¼ƒå°‘çš„é¡åˆ¥")
        
        return distribution
    
    def find_duplicate_labels(self):
        """å°‹æ‰¾é‡è¤‡æ¨™ç±¤"""
        
        # è¼‰å…¥åœ–åƒä¸¦è¨ˆç®—é›œæ¹Š
        image_hashes = {}
        duplicates = []
        
        for _, row in self.labels_df.iterrows():
            img_path = Path("data/training/images") / row['filename']
            
            if img_path.exists():
                image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                img_hash = hashlib.md5(image.tobytes()).hexdigest()
                
                if img_hash in image_hashes:
                    duplicates.append({
                        'hash': img_hash,
                        'files': [image_hashes[img_hash], row['filename']],
                        'labels': [self.get_label_for_file(image_hashes[img_hash]), row['label']]
                    })
                else:
                    image_hashes[img_hash] = row['filename']
        
        if duplicates:
            print(f"ç™¼ç¾ {len(duplicates)} çµ„é‡è¤‡åœ–åƒ")
            for dup in duplicates:
                print(f"æª”æ¡ˆ: {dup['files']}, æ¨™ç±¤: {dup['labels']}")
        
        return duplicates
    
    def validate_labels_with_model(self, model_path="data/models/model.keras"):
        """ä½¿ç”¨ç¾æœ‰æ¨¡å‹é©—è­‰æ¨™ç±¤"""
        
        if not Path(model_path).exists():
            print("æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³éé©—è­‰")
            return
        
        model = tf.keras.models.load_model(model_path)
        inconsistencies = []
        
        for _, row in self.labels_df.iterrows():
            img_path = Path("data/training/images") / row['filename']
            
            if img_path.exists():
                # è¼‰å…¥ä¸¦é è™•ç†åœ–åƒ
                image = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                processed = preprocess_for_prediction(image)
                
                # æ¨¡å‹é æ¸¬
                prediction = model.predict(processed, verbose=0)
                predicted_class = np.argmax(prediction)
                confidence = np.max(prediction)
                
                # æª¢æŸ¥ä¸ä¸€è‡´æ€§
                if predicted_class != row['label'] and confidence > 0.8:
                    inconsistencies.append({
                        'filename': row['filename'],
                        'human_label': row['label'],
                        'model_prediction': predicted_class,
                        'confidence': confidence
                    })
        
        if inconsistencies:
            print(f"ç™¼ç¾ {len(inconsistencies)} å€‹å¯èƒ½çš„æ¨™è¨»éŒ¯èª¤")
            for inc in inconsistencies[:10]:  # åªé¡¯ç¤ºå‰ 10 å€‹
                print(f"{inc['filename']}: äººå·¥={inc['human_label']}, "
                      f"æ¨¡å‹={inc['model_prediction']} (ä¿¡å¿ƒåº¦={inc['confidence']:.3f})")
        
        return inconsistencies
```

### 3. è³‡æ–™é è™•ç†éšæ®µ

#### é€²éšè³‡æ–™å¢å¼·
```python
class AdvancedDataAugmentation:
    """é€²éšè³‡æ–™å¢å¼·å™¨"""
    
    def __init__(self, augmentation_factor=3):
        self.aug_factor = augmentation_factor
        
    def augment_dataset(self, images, labels):
        """å°æ•´å€‹è³‡æ–™é›†é€²è¡Œå¢å¼·"""
        
        augmented_images = []
        augmented_labels = []
        
        for img, label in zip(images, labels):
            # åŸå§‹åœ–åƒ
            augmented_images.append(img)
            augmented_labels.append(label)
            
            # ç”Ÿæˆå¢å¼·è®Šé«”
            for _ in range(self.aug_factor):
                aug_img = self.apply_random_augmentation(img)
                augmented_images.append(aug_img)
                augmented_labels.append(label)
        
        return np.array(augmented_images), np.array(augmented_labels)
    
    def apply_random_augmentation(self, image):
        """éš¨æ©Ÿæ‡‰ç”¨å¢å¼·æŠ€è¡“"""
        
        aug_image = image.copy()
        
        # éš¨æ©Ÿé¸æ“‡å¢å¼·æŠ€è¡“
        augmentations = [
            self.rotate_image,
            self.scale_image,
            self.translate_image,
            self.add_noise,
            self.adjust_brightness,
            self.adjust_contrast
        ]
        
        # éš¨æ©Ÿé¸æ“‡ 1-3 ç¨®å¢å¼·æŠ€è¡“
        num_augs = random.randint(1, 3)
        selected_augs = random.sample(augmentations, num_augs)
        
        for aug_func in selected_augs:
            aug_image = aug_func(aug_image)
        
        return aug_image
    
    def rotate_image(self, image, max_angle=15):
        """æ—‹è½‰åœ–åƒ"""
        angle = random.uniform(-max_angle, max_angle)
        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        rotated = cv2.warpAffine(image, rotation_matrix, (width, height))
        
        return rotated
    
    def scale_image(self, image, scale_range=(0.8, 1.2)):
        """ç¸®æ”¾åœ–åƒ"""
        scale = random.uniform(*scale_range)
        height, width = image.shape[:2]
        
        new_height, new_width = int(height * scale), int(width * scale)
        scaled = cv2.resize(image, (new_width, new_height))
        
        # è£å‰ªæˆ–å¡«å……åˆ°åŸå§‹å¤§å°
        if scale > 1.0:
            # ç¸®æ”¾å¾Œè¼ƒå¤§ï¼Œéœ€è¦è£å‰ª
            start_y = (new_height - height) // 2
            start_x = (new_width - width) // 2
            scaled = scaled[start_y:start_y+height, start_x:start_x+width]
        else:
            # ç¸®æ”¾å¾Œè¼ƒå°ï¼Œéœ€è¦å¡«å……
            padded = np.zeros_like(image)
            start_y = (height - new_height) // 2
            start_x = (width - new_width) // 2
            padded[start_y:start_y+new_height, start_x:start_x+new_width] = scaled
            scaled = padded
        
        return scaled
    
    def add_noise(self, image, noise_factor=0.1):
        """æ·»åŠ é«˜æ–¯é›œè¨Š"""
        noise = np.random.normal(0, noise_factor * 255, image.shape)
        noisy = image.astype(np.float32) + noise
        noisy = np.clip(noisy, 0, 255).astype(np.uint8)
        
        return noisy
```

## ğŸ§  æ¨¡å‹è¨“ç·´éšæ®µ

### é€²éšè¨“ç·´ç®¡é“
```python
class AdvancedTrainingPipeline:
    """é€²éšè¨“ç·´ç®¡é“"""
    
    def __init__(self, config):
        self.config = config
        self.model = None
        self.history = None
        
    def train_with_cross_validation(self, X, y, k_folds=5):
        """ä½¿ç”¨äº¤å‰é©—è­‰è¨“ç·´"""
        
        from sklearn.model_selection import StratifiedKFold
        
        kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)
        cv_scores = []
        best_model = None
        best_score = 0
        
        for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y.argmax(axis=1))):
            print(f"\n=== è¨“ç·´ç¬¬ {fold + 1} æŠ˜ ===")
            
            # åˆ†å‰²è³‡æ–™
            X_train_fold, X_val_fold = X[train_idx], X[val_idx]
            y_train_fold, y_val_fold = y[train_idx], y[val_idx]
            
            # å»ºç«‹æ–°æ¨¡å‹
            model = self.create_model()
            
            # è¨“ç·´æ¨¡å‹
            history = model.fit(
                X_train_fold, y_train_fold,
                validation_data=(X_val_fold, y_val_fold),
                epochs=self.config['epochs'],
                batch_size=self.config['batch_size'],
                callbacks=self.create_callbacks(fold),
                verbose=1
            )
            
            # è©•ä¼°æ¨¡å‹
            val_score = model.evaluate(X_val_fold, y_val_fold, verbose=0)[1]
            cv_scores.append(val_score)
            
            print(f"ç¬¬ {fold + 1} æŠ˜é©—è­‰æº–ç¢ºç‡: {val_score:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_score > best_score:
                best_score = val_score
                best_model = model
        
        print(f"\näº¤å‰é©—è­‰çµæœ:")
        print(f"å¹³å‡æº–ç¢ºç‡: {np.mean(cv_scores):.4f} Â± {np.std(cv_scores):.4f}")
        print(f"æœ€ä½³æº–ç¢ºç‡: {best_score:.4f}")
        
        return best_model, cv_scores
    
    def train_with_early_stopping(self, X_train, y_train, X_val, y_val):
        """ä½¿ç”¨æ—©åœæ©Ÿåˆ¶è¨“ç·´"""
        
        model = self.create_model()
        
        # æ—©åœå›èª¿
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=10,
            restore_best_weights=True,
            verbose=1
        )
        
        # å­¸ç¿’ç‡è¡°æ¸›
        lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        )
        
        # æ¨¡å‹æª¢æŸ¥é»
        checkpoint = tf.keras.callbacks.ModelCheckpoint(
            filepath='checkpoints/best_model_epoch_{epoch:02d}.keras',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        )
        
        # è¨“ç·´æ¨¡å‹
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=self.config['max_epochs'],
            batch_size=self.config['batch_size'],
            callbacks=[early_stopping, lr_scheduler, checkpoint],
            verbose=1
        )
        
        return model, history
    
    def hyperparameter_tuning(self, X_train, y_train, X_val, y_val):
        """è¶…åƒæ•¸èª¿æ•´"""
        
        import itertools
        
        # å®šç¾©è¶…åƒæ•¸æœå°‹ç©ºé–“
        param_grid = {
            'learning_rate': [0.001, 0.0005, 0.0001],
            'batch_size': [16, 32, 64],
            'dropout_rate': [0.3, 0.5, 0.7],
            'num_filters': [16, 32, 64]
        }
        
        best_params = None
        best_score = 0
        results = []
        
        # ç¶²æ ¼æœå°‹
        param_combinations = list(itertools.product(*param_grid.values()))
        
        for i, params in enumerate(param_combinations):
            param_dict = dict(zip(param_grid.keys(), params))
            print(f"\n=== æ¸¬è©¦åƒæ•¸çµ„åˆ {i+1}/{len(param_combinations)} ===")
            print(f"åƒæ•¸: {param_dict}")
            
            try:
                # ä½¿ç”¨ç•¶å‰åƒæ•¸å»ºç«‹å’Œè¨“ç·´æ¨¡å‹
                model = self.create_model_with_params(param_dict)
                
                history = model.fit(
                    X_train, y_train,
                    validation_data=(X_val, y_val),
                    epochs=20,  # è¼ƒå°‘çš„ epochs ç”¨æ–¼å¿«é€Ÿè©•ä¼°
                    batch_size=param_dict['batch_size'],
                    verbose=0
                )
                
                # è©•ä¼°æ¨¡å‹
                val_score = max(history.history['val_accuracy'])
                
                results.append({
                    'params': param_dict,
                    'score': val_score
                })
                
                print(f"é©—è­‰æº–ç¢ºç‡: {val_score:.4f}")
                
                if val_score > best_score:
                    best_score = val_score;
                    best_params = param_dict;
                    
            except Exception as e:
                print(f"åƒæ•¸çµ„åˆå¤±æ•—: {e}")
                continue
        
        print(f"\n=== è¶…åƒæ•¸èª¿æ•´çµæœ ===")
        print(f"æœ€ä½³åƒæ•¸: {best_params}")
        print(f"æœ€ä½³åˆ†æ•¸: {best_score:.4f}")
        
        return best_params, results
```

## ğŸƒâ€â™‚ï¸ ResNet50 è¨“ç·´æµç¨‹è¨­è¨ˆ

### ResNet50 é·ç§»å­¸ç¿’ç®¡é“
```python
# run_training.py - ResNet50 è¨“ç·´å…¥å£
def main_resnet50_training_pipeline():
    """ResNet50 ä¸»è¦è¨“ç·´æµç¨‹"""
    
    print("ğŸš€ é–‹å§‹ ResNet50 è¨“ç·´æµç¨‹...")
    
    # 1. è³‡æ–™è¼‰å…¥èˆ‡é è™•ç†
    print("ğŸ“Š è¼‰å…¥è¨“ç·´è³‡æ–™...")
    train_data, val_data, test_data = load_resnet50_training_data()
    
    # 2. å»ºç«‹ ResNet50 æ¨¡å‹
    print("ğŸ§  å»ºç«‹ ResNet50 æ¨¡å‹...")
    model = create_resnet50_digit_model(pretrained=True)
    
    # 3. å…©éšæ®µè¨“ç·´ç­–ç•¥
    print("ğŸ¯ é–‹å§‹å…©éšæ®µè¨“ç·´...")
    
    # éšæ®µ 1: è¨“ç·´åˆ†é¡é ­
    print("âš¡ éšæ®µ 1: è¨“ç·´åˆ†é¡é ­ (å‡çµé è¨“ç·´å±¤)")
    model, history_1 = train_stage_1(model, train_data, val_data)
    
    # éšæ®µ 2: å¾®èª¿æ•´å€‹ç¶²è·¯
    print("ğŸ”§ éšæ®µ 2: å¾®èª¿æ•´å€‹ç¶²è·¯")
    model, history_2 = train_stage_2(model, train_data, val_data)
    
    # 4. æ¨¡å‹è©•ä¼°
    print("ğŸ“ˆ è©•ä¼°æœ€çµ‚æ¨¡å‹...")
    evaluation_results = evaluate_resnet50_model(model, test_data)
    
    # 5. æ¨¡å‹å„²å­˜
    print("ğŸ’¾ å„²å­˜è¨“ç·´å®Œæˆçš„æ¨¡å‹...")
    save_final_model(model, evaluation_results)
    
    print("âœ… ResNet50 è¨“ç·´å®Œæˆ!")
    return model, history_1, history_2, evaluation_results

def train_stage_1(model, train_data, val_data):
    """éšæ®µ 1: å‡çµé è¨“ç·´å±¤ï¼Œåªè¨“ç·´åˆ†é¡é ­"""
    
    # å‡çµ ResNet50 åŸºç¤æ¨¡å‹
    model.layers[1].trainable = False  # base_model å‡çµ
    
    # ç·¨è­¯æ¨¡å‹
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy', 'top_3_accuracy']
    )
    
    # è¨“ç·´é…ç½®
    callbacks_stage1 = [
        tf.keras.callbacks.ModelCheckpoint(
            'data/models/checkpoints/stage1_best.keras',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        tf.keras.callbacks.TensorBoard(
            log_dir='logs/stage1',
            histogram_freq=1
        )
    ]
    
    # åŸ·è¡Œè¨“ç·´
    history = model.fit(
        train_data,
        validation_data=val_data,
        epochs=cfg.TRAINING.epochs_stage1,
        callbacks=callbacks_stage1,
        verbose=1
    )
    
    print(f"éšæ®µ 1 å®Œæˆ - æœ€ä½³é©—è­‰æº–ç¢ºç‡: {max(history.history['val_accuracy']):.4f}")
    return model, history

def train_stage_2(model, train_data, val_data):
    """éšæ®µ 2: è§£å‡ä¸¦å¾®èª¿æ•´å€‹ç¶²è·¯"""
    
    # è§£å‡ ResNet50 åŸºç¤æ¨¡å‹
    model.layers[1].trainable = True
    
    # å‡çµå‰é¢çš„å±¤ï¼Œåªå¾®èª¿å¾Œé¢çš„å±¤
    for layer in model.layers[1].layers[:-cfg.MODEL.fine_tune_layers]:
        layer.trainable = False
    
    # é‡æ–°ç·¨è­¯ (ä½¿ç”¨æ›´å°çš„å­¸ç¿’ç‡)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=cfg.TRAINING.learning_rate_stage2),
        loss='categorical_crossentropy',
        metrics=['accuracy', 'top_3_accuracy']
    )
    
    # è¨“ç·´é…ç½®
    callbacks_stage2 = [
        tf.keras.callbacks.ModelCheckpoint(
            'data/models/checkpoints/stage2_best.keras',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        tf.keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=cfg.TRAINING.early_stopping_patience,
            restore_best_weights=True,
            verbose=1
        ),
        tf.keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=1e-7,
            verbose=1
        ),
        tf.keras.callbacks.TensorBoard(
            log_dir='logs/stage2',
            histogram_freq=1
        )
    ]
    
    # åŸ·è¡Œå¾®èª¿
    history = model.fit(
        train_data,
        validation_data=val_data,
        epochs=cfg.TRAINING.epochs_stage2,
        callbacks=callbacks_stage2,
        verbose=1
    )
    
    print(f"éšæ®µ 2 å®Œæˆ - æœ€ä½³é©—è­‰æº–ç¢ºç‡: {max(history.history['val_accuracy']):.4f}")
    return model, history

def load_resnet50_training_data():
    """è¼‰å…¥ ResNet50 å°ˆç”¨è¨“ç·´è³‡æ–™"""
    
    # è³‡æ–™è·¯å¾‘
    images_dir = Path("data/training/images")
    labels_file = Path("data/training/labels.csv")
    
    # è¼‰å…¥æ¨™ç±¤
    labels_df = pd.read_csv(labels_file)
    
    # è¼‰å…¥å½±åƒ
    images = []
    labels = []
    
    for _, row in labels_df.iterrows():
        img_path = images_dir / row['filename']
        if img_path.exists():
            # è¼‰å…¥ä¸¦é è™•ç†å½±åƒ
            img = cv2.imread(str(img_path))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = cv2.resize(img, (224, 224))
            
            images.append(img)
            labels.append(row['label'])
    
    # è½‰æ›ç‚º numpy é™£åˆ—
    images = np.array(images, dtype=np.float32)
    labels = np.array(labels)
    
    # æ¨™ç±¤è½‰ç‚º one-hot ç·¨ç¢¼
    labels_onehot = tf.keras.utils.to_categorical(labels, num_classes=10)
    
    # åˆ†å‰²è³‡æ–™é›†
    train_images, test_images, train_labels, test_labels = train_test_split(
        images, labels_onehot, test_size=0.2, random_state=42, stratify=labels
    )
    
    train_images, val_images, train_labels, val_labels = train_test_split(
        train_images, train_labels, test_size=0.2, random_state=42
    )
    
    # å»ºç«‹è³‡æ–™æ“´å¢ç”Ÿæˆå™¨
    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=tf.keras.applications.resnet50.preprocess_input,
        **cfg.DATA_AUGMENTATION
    )
    
    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=tf.keras.applications.resnet50.preprocess_input
    )
    
    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
        preprocessing_function=tf.keras.applications.resnet50.preprocess_input
    )
    
    # å»ºç«‹è³‡æ–™ç”Ÿæˆå™¨
    train_generator = train_datagen.flow(
        train_images, train_labels,
        batch_size=cfg.MODEL.batch_size,
        shuffle=True
    )
    
    val_generator = val_datagen.flow(
        val_images, val_labels,
        batch_size=cfg.MODEL.batch_size,
        shuffle=False
    )
    
    test_generator = test_datagen.flow(
        test_images, test_labels,
        batch_size=cfg.MODEL.batch_size,
        shuffle=False
    )
    
    return train_generator, val_generator, test_generator

def evaluate_resnet50_model(model, test_data):
    """å…¨é¢è©•ä¼° ResNet50 æ¨¡å‹"""
    
    print("ğŸ“Š é–‹å§‹æ¨¡å‹è©•ä¼°...")
    
    # åŸºæœ¬è©•ä¼°
    test_loss, test_accuracy, test_top3_accuracy = model.evaluate(
        test_data, verbose=1
    )
    
    print(f"æ¸¬è©¦é›†æº–ç¢ºç‡: {test_accuracy:.4f}")
    print(f"Top-3 æº–ç¢ºç‡: {test_top3_accuracy:.4f}")
    
    # è©³ç´°é æ¸¬åˆ†æ
    predictions = model.predict(test_data, verbose=1)
    y_pred = np.argmax(predictions, axis=1)
    
    # ç²å–çœŸå¯¦æ¨™ç±¤
    y_true = []
    for i, (_, labels_batch) in enumerate(test_data):
        y_true.extend(np.argmax(labels_batch, axis=1))
        if i >= len(test_data) - 1:  # ç¢ºä¿è¦†è“‹æ‰€æœ‰è³‡æ–™
            break
    
    y_true = np.array(y_true[:len(y_pred)])  # ç¢ºä¿é•·åº¦ä¸€è‡´
    
    # åˆ†é¡å ±å‘Š
    from sklearn.metrics import classification_report, confusion_matrix
    
    print("\nåˆ†é¡å ±å‘Š:")
    print(classification_report(y_true, y_pred, digits=4))
    
    # æ··æ·†çŸ©é™£
    cm = confusion_matrix(y_true, y_pred)
    print("\næ··æ·†çŸ©é™£:")
    print(cm)
    
    # æ¯å€‹é¡åˆ¥çš„æº–ç¢ºç‡
    class_accuracies = cm.diagonal() / cm.sum(axis=1)
    print("\nå„æ•¸å­—è­˜åˆ¥æº–ç¢ºç‡:")
    for digit in range(10):
        print(f"æ•¸å­— {digit}: {class_accuracies[digit]:.4f}")
    
    # ä¿¡å¿ƒåº¦åˆ†æ
    confidence_scores = np.max(predictions, axis=1)
    print(f"\nå¹³å‡ä¿¡å¿ƒåº¦: {np.mean(confidence_scores):.4f}")
    print(f"ä¿¡å¿ƒåº¦æ¨™æº–å·®: {np.std(confidence_scores):.4f}")
    
    # ä½ä¿¡å¿ƒåº¦æ¨£æœ¬åˆ†æ
    low_confidence_indices = np.where(confidence_scores < cfg.MODEL.confidence_threshold)[0]
    print(f"ä½ä¿¡å¿ƒåº¦æ¨£æœ¬æ•¸é‡: {len(low_confidence_indices)} ({len(low_confidence_indices)/len(y_pred)*100:.2f}%)")
    
    evaluation_results = {
        'test_accuracy': test_accuracy,
        'test_top3_accuracy': test_top3_accuracy,
        'test_loss': test_loss,
        'confusion_matrix': cm,
        'classification_report': classification_report(y_true, y_pred, output_dict=True),
        'class_accuracies': class_accuracies,
        'mean_confidence': np.mean(confidence_scores),
        'low_confidence_ratio': len(low_confidence_indices)/len(y_pred)
    }
    
    return evaluation_results
```

### ResNet50 è¶…åƒæ•¸èª¿æ•´
```python
def resnet50_hyperparameter_tuning():
    """ResNet50 è¶…åƒæ•¸èª¿æ•´"""
    
    import optuna
    
    def objective(trial):
        """Optuna ç›®æ¨™å‡½å¼"""
        
        # è¶…åƒæ•¸æœå°‹ç©ºé–“
        learning_rate_stage1 = trial.suggest_float('lr_stage1', 1e-4, 1e-2, log=True)
        learning_rate_stage2 = trial.suggest_float('lr_stage2', 1e-6, 1e-3, log=True)
        batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])
        fine_tune_layers = trial.suggest_int('fine_tune_layers', 10, 50)
        dropout_rate = trial.suggest_float('dropout_rate', 0.3, 0.7)
        
        # å»ºç«‹æ¨¡å‹
        model = create_resnet50_with_params(
            dropout_rate=dropout_rate,
            fine_tune_layers=fine_tune_layers
        )
        
        # è¼‰å…¥è³‡æ–™
        train_data, val_data, _ = load_resnet50_training_data(batch_size=batch_size)
        
        # è¨“ç·´æ¨¡å‹
        try:
            # éšæ®µ 1
            model.layers[1].trainable = False
            model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_stage1),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
            
            model.fit(train_data, validation_data=val_data, epochs=5, verbose=0)
            
            # éšæ®µ 2
            model.layers[1].trainable = True
            for layer in model.layers[1].layers[:-fine_tune_layers]:
                layer.trainable = False
                
            model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_stage2),
                loss='categorical_crossentropy',
                metrics=['accuracy']
            )
            
            history = model.fit(train_data, validation_data=val_data, epochs=10, verbose=0)
            
            # å›å‚³æœ€ä½³é©—è­‰æº–ç¢ºç‡
            best_val_accuracy = max(history.history['val_accuracy'])
            return best_val_accuracy
            
        except Exception as e:
            print(f"è¨“ç·´å¤±æ•—: {e}")
            return 0.0
    
    # å»ºç«‹ç ”ç©¶
    study = optuna.create_study(direction='maximize')
    study.optimize(objective, n_trials=50)
    
    print("æœ€ä½³è¶…åƒæ•¸:")
    print(study.best_params)
    print(f"æœ€ä½³é©—è­‰æº–ç¢ºç‡: {study.best_value:.4f}")
    
    return study.best_params
```
