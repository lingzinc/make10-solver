# æŠ€è¡“æ¶æ§‹æ–‡ä»¶

> ğŸ—ï¸ Make10 è‡ªå‹•åŒ–ç³»çµ±çš„æŠ€è¡“æ¶æ§‹ã€æ ¸å¿ƒæ¼”ç®—æ³•èˆ‡å¯¦ä½œç´°ç¯€

## ğŸ¯ ç³»çµ±è¨­è¨ˆåŸå‰‡

### æ¶æ§‹ç†å¿µ
- **æ¨¡çµ„åŒ–è¨­è¨ˆ** - åŠŸèƒ½ç¨ç«‹ã€ä»‹é¢æ¸…æ™°çš„å…ƒä»¶æ¶æ§‹
- **å¯æ“´å±•æ€§** - æ”¯æ´æ–°åŠŸèƒ½æ¨¡çµ„çš„ç†±æ’æ‹”
- **é«˜æ•ˆèƒ½** - æœ€ä½³åŒ–è¨˜æ†¶é«”ä½¿ç”¨èˆ‡ CPU æ•ˆèƒ½
- **å®¹éŒ¯æ©Ÿåˆ¶** - å®Œå–„çš„éŒ¯èª¤è™•ç†èˆ‡æ¢å¾©ç­–ç•¥
- **å¯ç¶­è­·æ€§** - æ¸…æ™°çš„ç¨‹å¼ç¢¼çµæ§‹èˆ‡æ–‡ä»¶

### æ¶æ§‹æ¨¡å¼
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ§åˆ¶å±¤        â”‚    â”‚    æ¥­å‹™é‚è¼¯å±¤    â”‚    â”‚    è³‡æ–™å±¤       â”‚
â”‚  (Control)      â”‚â”€â”€â”€â”€â”‚   (Business)    â”‚â”€â”€â”€â”€â”‚    (Data)       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 éµç›¤ç›£è½/è¢å¹•æ§åˆ¶      éŠæˆ²é‚è¼¯/AI æ¨ç†       é…ç½®ç®¡ç†/æ¨¡å‹å­˜å„²
```

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "Make10 è‡ªå‹•åŒ–ç³»çµ±"
        A[ç³»çµ±å…¥å£ run_system.py]
        B[æ ¸å¿ƒæ§åˆ¶å™¨ core/main.py]
        
        subgraph "è‡ªå‹•åŒ–æ¨¡çµ„"
            C[è¢å¹•å·¥å…· screen_utils.py]
            D[éµç›¤ç›£è½ keyboard_listener.py]
        end
        
        subgraph "AI æ¨¡çµ„ (é–‹ç™¼ä¸­)"
            E[æ¨¡å‹ç®¡ç†å™¨]
            F[é æ¸¬å™¨]
        end
        
        subgraph "é…ç½®ç³»çµ±"
            G[è¨­å®šæª” settings.py]
            H[å¸¸æ•¸å®šç¾© constants.py]
        end
        
        subgraph "è³‡æ–™å±¤"
            I[æ¨¡å‹æª”æ¡ˆ .keras]
            J[è¨“ç·´è³‡æ–™]
            K[æ¨¡æ¿è³‡æº]
        end
    end
    
    A --> B
    B --> C
    B --> D
    B --> E
    B --> F
    C --> G
    D --> G
    E --> I
    F --> I
    G --> H
```

## ğŸ’» å¯¦ä½œç‹€æ³

### âœ… å·²å¯¦ä½œåŠŸèƒ½
| æ¨¡çµ„ | æª”æ¡ˆè·¯å¾‘ | åŠŸèƒ½ç‹€æ…‹ | èªªæ˜ |
|------|----------|----------|------|
| **æ ¸å¿ƒç³»çµ±** | `src/core/main.py` | âœ… å®Œæˆ | ç³»çµ±å•Ÿå‹•ã€åˆå§‹åŒ–ã€ä¸»å¾ªç’° |
| **è¢å¹•å·¥å…·** | `src/automation/screen_utils.py` | âœ… å®Œæˆ | è¢å¹•æ“·å–ã€æ»‘é¼ æ§åˆ¶ã€æ¨¡æ¿åŒ¹é… |
| **éµç›¤ç›£è½** | `src/automation/keyboard_listener.py` | âœ… å®Œæˆ | ç†±éµç›£è½ã€å®‰å…¨é€€å‡ºæ©Ÿåˆ¶ |
| **é…ç½®ç³»çµ±** | `config/settings.py` | âœ… å®Œæˆ | åƒæ•¸ç®¡ç†ã€è·¯å¾‘é…ç½® |
| **æ¸¬è©¦å¥—ä»¶** | `tests/` | âœ… å®Œæˆ | å–®å…ƒæ¸¬è©¦ã€æ¨¡æ“¬æ¸¬è©¦ |

### ğŸš§ é–‹ç™¼ä¸­åŠŸèƒ½
| æ¨¡çµ„ | æª”æ¡ˆè·¯å¾‘ | é–‹ç™¼ç‹€æ…‹ | è¨ˆç•« |
|------|----------|----------|------|
| **AI æ¨¡å‹** | `src/ai/` | ğŸš§ è¦åŠƒä¸­ | CNN æ•¸å­—è­˜åˆ¥æ¨¡å‹ |
| **æ¨™ç±¤å·¥å…·** | `src/labeling/` | ğŸš§ è¦åŠƒä¸­ | è¨“ç·´è³‡æ–™æ¨™è¨»å·¥å…· |
| **è¨“ç·´æµç¨‹** | `run_training.py` | ğŸš§ é–‹ç™¼ä¸­ | æ¨¡å‹è¨“ç·´è‡ªå‹•åŒ– |

## ğŸ”§ æŠ€è¡“æ£§è©³è§£

### æ ¸å¿ƒä¾è³´å¥—ä»¶
```toml
# é›»è…¦è¦–è¦ºèˆ‡å½±åƒè™•ç†
opencv-python = "4.12.0.88"     # å½±åƒè™•ç†æ ¸å¿ƒ
numpy = "2.1.3"                 # æ•¸å€¼è¨ˆç®—åŸºç¤
pillow = "11.3.0"               # å½±åƒæ ¼å¼æ”¯æ´

# æ©Ÿå™¨å­¸ç¿’æ¡†æ¶
tensorflow = "2.19.0"           # æ·±åº¦å­¸ç¿’æ¡†æ¶

# è‡ªå‹•åŒ–æ§åˆ¶
pynput = "1.8.1"               # éµç›¤æ»‘é¼ æ§åˆ¶
mss = "10.0.0"                 # é«˜æ•ˆèƒ½è¢å¹•æ“·å–

# è³‡æ–™è™•ç†èˆ‡å·¥å…·
pandas = "2.3.1"               # è³‡æ–™åˆ†æ
loguru = "0.7.3"               # æ—¥èªŒç³»çµ±
easydict = "1.13"              # é…ç½®ç®¡ç†
```

### æ¶æ§‹å…ƒä»¶èªªæ˜

#### 1. è‡ªå‹•åŒ–æ§åˆ¶å±¤
```python
# è¢å¹•å·¥å…·ç¯„ä¾‹
from src.automation.screen_utils import (
    capture_screen,      # è¢å¹•æ“·å–
    click_at_position,   # ç²¾ç¢ºé»æ“Š
    find_reset_button,   # æ¨¡æ¿åŒ¹é…
    switch_screen        # è¦–çª—åˆ‡æ›
)

# ä½¿ç”¨ç¯„ä¾‹
screenshot = capture_screen()           # æ“·å–è¢å¹•
success = click_at_position(100, 200)   # é»æ“Šåº§æ¨™
switch_screen()                         # Alt+Tab åˆ‡æ›
```

#### 2. é…ç½®ç®¡ç†ç³»çµ±
```python
from config.settings import cfg

# è·¯å¾‘é…ç½®
model_path = cfg.PATHS.MODEL.main_model
training_dir = cfg.PATHS.TRAINING.images_dir

# ç³»çµ±åƒæ•¸
click_delay = cfg.AUTOMATION.click_delay
exit_key = cfg.SYSTEM.exit_key

# å½±åƒè™•ç†åƒæ•¸
cell_size = cfg.IMAGE.PROCESSING.cell_size
confidence = cfg.MODEL.confidence_threshold
```

#### 3. æ—¥èªŒç³»çµ±
```python
from loguru import logger

# å¤šå±¤ç´šæ—¥èªŒè¼¸å‡º
logger.debug("é™¤éŒ¯è³‡è¨Š")     # é–‹ç™¼éšæ®µ
logger.info("ä¸€èˆ¬è³‡è¨Š")      # æ­£å¸¸é‹è¡Œ
logger.warning("è­¦å‘Šè¨Šæ¯")   # æ³¨æ„äº‹é …  
logger.error("éŒ¯èª¤è³‡è¨Š")     # éŒ¯èª¤è™•ç†

# è‡ªå‹•æª”æ¡ˆè¼ªè½‰
# logs/make10_system.log (ä¿ç•™ 7 å¤©)
```

## ğŸ§  ResNet50 AI æ¨¡å‹æ¶æ§‹

### ResNet50 æ¨¡å‹è¨­è¨ˆ
```python
# åŸºæ–¼ ResNet50 çš„æ•¸å­—è­˜åˆ¥æ¶æ§‹
def create_resnet50_digit_model(pretrained=True):
    """å»ºç«‹ ResNet50 æ•¸å­—è­˜åˆ¥æ¨¡å‹"""
    
    # è¼‰å…¥ ResNet50 é è¨“ç·´æ¨¡å‹
    base_model = tf.keras.applications.ResNet50(
        weights='imagenet' if pretrained else None,
        include_top=False,
        input_shape=(224, 224, 3)
    )
    
    # å»ºç«‹å®Œæ•´æ¨¡å‹
    model = tf.keras.Sequential([
        # è¼¸å…¥å±¤
        tf.keras.layers.Input(shape=(224, 224, 3)),
        
        # ResNet50 ç‰¹å¾µæå–å™¨
        base_model,
        
        # å…¨åŸŸå¹³å‡æ± åŒ–
        tf.keras.layers.GlobalAveragePooling2D(),
        
        # åˆ†é¡é ­
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dense(10, activation='softmax')  # 10 é¡åˆ¥æ•¸å­—
    ])
    
    return model

def create_resnet50_ensemble():
    """å»ºç«‹ ResNet50 é›†æˆæ¨¡å‹"""
    
    # å»ºç«‹å¤šå€‹ç•¥æœ‰ä¸åŒçš„ ResNet50 æ¨¡å‹
    models = []
    
    for i in range(3):  # 3 å€‹æ¨¡å‹é›†æˆ
        model = create_resnet50_digit_model(pretrained=True)
        
        # æ·»åŠ äº›è¨±éš¨æ©Ÿæ€§
        if i > 0:
            # ä¸åŒçš„ dropout ç‡
            model.layers[-3] = tf.keras.layers.Dropout(0.5 + i * 0.1)
        
        models.append(model)
    
    return models
```

### é·ç§»å­¸ç¿’ç­–ç•¥
```python
def implement_transfer_learning_strategy():
    """å¯¦ä½œé·ç§»å­¸ç¿’ç­–ç•¥"""
    
    strategies = {
        'feature_extraction': {
            'description': 'å‡çµé è¨“ç·´å±¤ï¼Œåªè¨“ç·´åˆ†é¡é ­',
            'base_trainable': False,
            'learning_rate': 0.001,
            'epochs': 10,
            'use_case': 'è³‡æ–™é‡è¼ƒå°‘æ™‚ä½¿ç”¨'
        },
        
        'fine_tuning': {
            'description': 'è§£å‡éƒ¨åˆ†å±¤é€²è¡Œå¾®èª¿',
            'base_trainable': True,
            'freeze_layers': -20,  # å‡çµå‰ N å±¤
            'learning_rate': 0.0001,
            'epochs': 20,
            'use_case': 'æœ‰è¶³å¤ è³‡æ–™æ™‚ä½¿ç”¨'
        },
        
        'full_training': {
            'description': 'å¾é ­è¨“ç·´æ•´å€‹ç¶²è·¯',
            'base_trainable': True,
            'freeze_layers': 0,
            'learning_rate': 0.0001,
            'epochs': 50,
            'use_case': 'å¤§é‡è³‡æ–™ä¸”è¨ˆç®—è³‡æºå……è¶³'
        }
    }
    
    return strategies
```

### è³‡æ–™æµç¨‹è¨­è¨ˆ (ResNet50)
```python
# ResNet50 å°ˆç”¨æ¨ç†æµç¨‹
def predict_digit_resnet50(image_region):
    """ResNet50 æ•¸å­—è­˜åˆ¥æ¨ç†"""
    
    # 1. å½±åƒé è™•ç† (224x224 RGB)
    processed = preprocess_for_resnet50(image_region)
    
    # 2. æ¨¡å‹æ¨ç†
    prediction = resnet50_model.predict(processed, verbose=0)
    
    # 3. çµæœå¾Œè™•ç†
    digit = np.argmax(prediction[0])
    confidence = np.max(prediction[0])
    all_probs = prediction[0]
    
    # 4. ä¿¡å¿ƒåº¦æª¢æŸ¥
    if confidence < cfg.MODEL.confidence_threshold:
        return None, confidence  # ä½ä¿¡å¿ƒåº¦æ¨£æœ¬
    
    return digit, confidence

def preprocess_for_resnet50(image_region):
    """ResNet50 å°ˆç”¨é è™•ç†"""
    
    # èª¿æ•´å¤§å°åˆ° 224x224
    resized = cv2.resize(image_region, (224, 224))
    
    # ç¢ºä¿ RGB æ ¼å¼
    if len(resized.shape) == 2:
        rgb_image = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB)
    elif resized.shape[2] == 1:
        rgb_image = np.repeat(resized, 3, axis=2)
    else:
        rgb_image = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    
    # ImageNet æ¨™æº–åŒ–
    normalized = tf.keras.applications.resnet50.preprocess_input(
        rgb_image.astype(np.float32)
    )
    
    # æ·»åŠ æ‰¹æ¬¡ç¶­åº¦
    return np.expand_dims(normalized, axis=0)

def ensemble_prediction(image_region, models):
    """é›†æˆæ¨¡å‹é æ¸¬"""
    
    predictions = []
    
    # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é æ¸¬
    for model in models:
        pred = model.predict(preprocess_for_resnet50(image_region), verbose=0)
        predictions.append(pred[0])
    
    # å¹³å‡é›†æˆ
    avg_prediction = np.mean(predictions, axis=0)
    
    # æŠ•ç¥¨é›†æˆ
    votes = [np.argmax(pred) for pred in predictions]
    vote_counts = np.bincount(votes, minlength=10)
    voted_digit = np.argmax(vote_counts)
    
    return {
        'average_prediction': {
            'digit': int(np.argmax(avg_prediction)),
            'confidence': float(np.max(avg_prediction)),
            'probabilities': avg_prediction.tolist()
        },
        'voting_prediction': {
            'digit': int(voted_digit),
            'votes': vote_counts.tolist(),
            'consensus': float(np.max(vote_counts) / len(models))
        }
    }
```

### æ¨¡å‹æœ€ä½³åŒ–æŠ€è¡“
```python
def optimize_resnet50_inference():
    """ResNet50 æ¨ç†æœ€ä½³åŒ–"""
    
    optimization_techniques = {
        'model_quantization': {
            'description': 'æ¨¡å‹é‡åŒ–æ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨',
            'implementation': '''
            converter = tf.lite.TFLiteConverter.from_keras_model(model)
            converter.optimizations = [tf.lite.Optimize.DEFAULT]
            tflite_model = converter.convert()
            '''
        },
        
        'batch_inference': {
            'description': 'æ‰¹æ¬¡æ¨ç†æå‡ååé‡',
            'implementation': '''
            # ç´¯ç©å¤šå€‹å½±åƒå†ä¸€æ¬¡æ¨ç†
            if len(batch_images) >= batch_size:
                predictions = model.predict(np.array(batch_images))
                batch_images.clear()
            '''
        },
        
        'model_pruning': {
            'description': 'æ¨¡å‹å‰ªæç§»é™¤ä¸é‡è¦çš„é€£æ¥',
            'implementation': '''
            import tensorflow_model_optimization as tfmot
            prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude
            pruned_model = prune_low_magnitude(model)
            '''
        },
        
        'mixed_precision': {
            'description': 'æ··åˆç²¾åº¦åŠ é€Ÿè¨“ç·´',
            'implementation': '''
            policy = tf.keras.mixed_precision.Policy('mixed_float16')
            tf.keras.mixed_precision.set_global_policy(policy)
            '''
        }
    }
    
    return optimization_techniques
```

## ğŸ“Š æ•ˆèƒ½æœ€ä½³åŒ–ç­–ç•¥

### è¨˜æ†¶é«”ç®¡ç†
- **å½±åƒè™•ç†**: ä½¿ç”¨ NumPy åŸåœ°æ“ä½œæ¸›å°‘è¨˜æ†¶é«”åˆ†é…
- **æ¨¡å‹æ¨ç†**: æ‰¹æ¬¡è™•ç†æå‡ GPU åˆ©ç”¨ç‡
- **è³‡æºé‡‹æ”¾**: è‡ªå‹•åƒåœ¾å›æ”¶èˆ‡è³‡æºæ¸…ç†

### CPU æœ€ä½³åŒ–
- **å¤šåŸ·è¡Œç·’**: åˆ†é›¢ UI æ“ä½œèˆ‡è¨ˆç®—ä»»å‹™
- **æ¼”ç®—æ³•**: é¸æ“‡æ™‚é–“è¤‡é›œåº¦è¼ƒä½çš„æ¼”ç®—æ³•
- **å¿«å–æ©Ÿåˆ¶**: å¸¸ç”¨è³‡æ–™èˆ‡è¨ˆç®—çµæœå¿«å–

### ç³»çµ±ç©©å®šæ€§
- **éŒ¯èª¤æ¢å¾©**: å®Œå–„çš„ä¾‹å¤–è™•ç†æ©Ÿåˆ¶
- **è¶…æ™‚æ§åˆ¶**: é¿å…ç„¡é™ç­‰å¾…çš„è¶…æ™‚æ©Ÿåˆ¶
- **è³‡æºç›£æ§**: è¨˜æ†¶é«”èˆ‡ CPU ä½¿ç”¨é‡ç›£æ§

## ğŸ”¬ æ¸¬è©¦ç­–ç•¥

### å–®å…ƒæ¸¬è©¦
```python
# æ¸¬è©¦è¦†è“‹ç¯„åœ
pytest tests/ --cov=src --cov-report=html

# ä¸»è¦æ¸¬è©¦æ¨¡çµ„
tests/test_screen_utils.py      # è¢å¹•å·¥å…·æ¸¬è©¦
tests/test_keyboard_listener.py # éµç›¤ç›£è½æ¸¬è©¦
tests/test_config_settings.py   # é…ç½®ç³»çµ±æ¸¬è©¦
```

### æ•´åˆæ¸¬è©¦
- **ç«¯åˆ°ç«¯æµç¨‹**: å®Œæ•´çš„è‡ªå‹•åŒ–æµç¨‹æ¸¬è©¦
- **æ¨¡æ“¬ç’°å¢ƒ**: ä½¿ç”¨ Mock ç‰©ä»¶æ¨¡æ“¬å¤–éƒ¨ä¾è³´
- **æ€§èƒ½æ¸¬è©¦**: éŸ¿æ‡‰æ™‚é–“èˆ‡è³‡æºä½¿ç”¨æ¸¬è©¦
    # 1. åœ–åƒé è™•ç†
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 2. é«˜æ–¯æ¨¡ç³Šå»é›œè¨Š
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # 3. è‡ªé©æ‡‰é‚Šç·£æª¢æ¸¬
    edges = cv2.Canny(blurred, 50, 150, apertureSize=3)
    
    # 4. éœå¤«ç›´ç·šæª¢æ¸¬
    lines = cv2.HoughLinesP(
        edges,
        rho=1,              # è·é›¢è§£æåº¦ (åƒç´ )
        theta=np.pi/180,    # è§’åº¦è§£æåº¦ (å¼§åº¦)
        threshold=100,      # æœ€å°æŠ•ç¥¨æ•¸
        minLineLength=50,   # æœ€å°ç·šæ®µé•·åº¦
        maxLineGap=10       # æœ€å¤§ç·šæ®µé–“éš™
    )
    
    # 5. ç·šæ®µåˆ†é¡èˆ‡éæ¿¾
    horizontal_lines = []
    vertical_lines = []
    
    if lines is not None:
        for line in lines:
            x1, y1, x2, y2 = line[0]
            
            # è¨ˆç®—ç·šæ®µè§’åº¦
            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            
            # åˆ†é¡æ°´å¹³å’Œå‚ç›´ç·šæ®µ
            if abs(angle) < 10 or abs(angle) > 170:
                horizontal_lines.append(line)
            elif abs(abs(angle) - 90) < 10:
                vertical_lines.append(line)
    
    # 6. ç·šæ®µåˆä½µèˆ‡æœ€ä½³åŒ–
    merged_h_lines = merge_collinear_lines(horizontal_lines)
    merged_v_lines = merge_collinear_lines(vertical_lines)
    
    return merged_h_lines, merged_v_lines

def merge_collinear_lines(lines, distance_threshold=10, angle_threshold=5):
    """åˆä½µå…±ç·šçš„ç·šæ®µ"""
    if not lines:
        return []
    
    merged_lines = []
    used = [False] * len(lines)
    
    for i, line1 in enumerate(lines):
        if used[i]:
            continue
            
        group = [line1]
        used[i] = True
        
        for j, line2 in enumerate(lines[i+1:], i+1):
            if used[j]:
                continue
                
            if are_lines_collinear(line1[0], line2[0], distance_threshold, angle_threshold):
                group.append(line2)
                used[j] = True
        
        # åˆä½µåŒçµ„ç·šæ®µ
        merged_line = merge_line_group(group)
        merged_lines.append(merged_line)
    
    return merged_lines
```

### 2. æŠ•å½±ç›´æ–¹åœ–é©—è­‰

#### åŸç†èªªæ˜
æŠ•å½±ç›´æ–¹åœ–æ˜¯ä¸€ç¨®è¼”åŠ©é©—è­‰ç¶²æ ¼æª¢æ¸¬çµæœçš„æŠ€è¡“ï¼Œé€šéåˆ†æåœ–åƒåœ¨æ°´å¹³å’Œå‚ç›´æ–¹å‘çš„åƒç´ ç´¯ç©åˆ†ä½ˆä¾†ç¢ºèªç¶²æ ¼ç·šä½ç½®ã€‚

#### å¯¦ä½œç´°ç¯€
```python
def projection_histogram_validation(edges, detected_lines):
    """ä½¿ç”¨æŠ•å½±ç›´æ–¹åœ–é©—è­‰ç¶²æ ¼æª¢æ¸¬çµæœ"""
    
    height, width = edges.shape
    
    # 1. è¨ˆç®—æŠ•å½±ç›´æ–¹åœ–
    horizontal_projection = np.sum(edges, axis=1)  # æ°´å¹³æŠ•å½±
    vertical_projection = np.sum(edges, axis=0)    # å‚ç›´æŠ•å½±
    
    # 2. å°‹æ‰¾æŠ•å½±å³°å€¼
    h_peaks = find_projection_peaks(horizontal_projection)
    v_peaks = find_projection_peaks(vertical_projection)
    
    # 3. èˆ‡æª¢æ¸¬åˆ°çš„ç·šæ®µæ¯”è¼ƒ
    validated_h_lines = validate_lines_with_projection(
        detected_lines['horizontal'], h_peaks, 'horizontal'
    )
    validated_v_lines = validate_lines_with_projection(
        detected_lines['vertical'], v_peaks, 'vertical'
    )
    
    return {
        'horizontal': validated_h_lines,
        'vertical': validated_v_lines,
        'confidence': calculate_validation_confidence(h_peaks, v_peaks)
    }

def find_projection_peaks(projection, prominence=0.3):
    """å°‹æ‰¾æŠ•å½±ç›´æ–¹åœ–ä¸­çš„å³°å€¼"""
    from scipy.signal import find_peaks
    
    # æ­£è¦åŒ–æŠ•å½±
    normalized = projection / np.max(projection)
    
    # å°‹æ‰¾å³°å€¼
    peaks, properties = find_peaks(
        normalized, 
        prominence=prominence,
        distance=20  # æœ€å°å³°å€¼é–“è·
    )
    
    return peaks
```

### 3. AI é æ¸¬æœ€ä½³åŒ–

#### æ‰¹æ¬¡è™•ç†æ¶æ§‹
```python
class OptimizedPredictor:
    """æœ€ä½³åŒ–çš„ AI é æ¸¬å™¨"""
    
    def __init__(self, model, batch_size=32):
        self.model = model
        self.batch_size = batch_size
        self.prediction_cache = {}
        
    def predict_board_optimized(self, cell_images):
        """æœ€ä½³åŒ–çš„ç›¤é¢é æ¸¬"""
        
        # 1. åœ–åƒé è™•ç†ç®¡é“
        processed_images = self.preprocess_batch(cell_images)
        
        # 2. æ‰¹æ¬¡é æ¸¬
        predictions = self.batch_predict(processed_images)
        
        # 3. å¾Œè™•ç†èˆ‡ä¿¡å¿ƒåº¦è©•ä¼°
        results = self.postprocess_predictions(predictions)
        
        # 4. å“è³ªæª¢æŸ¥èˆ‡ä¿®æ­£
        validated_results = self.validate_predictions(results, cell_images)
        
        return validated_results
    
    def preprocess_batch(self, images):
        """æ‰¹æ¬¡åœ–åƒé è™•ç†"""
        batch = np.zeros((len(images), 28, 28, 1), dtype=np.float32)
        
        for i, img in enumerate(images):
            # å°ºå¯¸æ­£è¦åŒ–
            resized = cv2.resize(img, (28, 28))
            
            # ç°éšè½‰æ›
            if len(resized.shape) == 3:
                gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
            else:
                gray = resized
            
            # æ•¸å€¼æ­£è¦åŒ–
            normalized = gray.astype(np.float32) / 255.0
            
            # åŠ å…¥æ‰¹æ¬¡ç¶­åº¦
            batch[i] = normalized.reshape(28, 28, 1)
        
        return batch
    
    def batch_predict(self, batch):
        """åŸ·è¡Œæ‰¹æ¬¡é æ¸¬"""
        return self.model.predict(batch, batch_size=self.batch_size)
    
    def postprocess_predictions(self, predictions):
        """å¾Œè™•ç†é æ¸¬çµæœ"""
        results = []
        
        for pred in predictions:
            # å–å¾—æœ€é«˜æ©Ÿç‡çš„é¡åˆ¥
            predicted_class = np.argmax(pred)
            confidence = np.max(pred)
            
            # è¨ˆç®—ç†µä½œç‚ºä¸ç¢ºå®šæ€§æŒ‡æ¨™
            entropy = -np.sum(pred * np.log(pred + 1e-8))
            
            results.append({
                'class': predicted_class,
                'confidence': confidence,
                'entropy': entropy,
                'probabilities': pred
            })
        
        return results
```

### 4. æ±‚è§£æ¼”ç®—æ³•æ¶æ§‹

#### å¤šå±¤æ¬¡æ±‚è§£ç­–ç•¥
```python
class HierarchicalSolver:
    """éšå±¤å¼æ±‚è§£å™¨"""
    
    def __init__(self):
        self.solvers = [
            BasicRecursiveSolver(),
            BranchBoundSolver(),
            GeneticAlgorithmSolver()
        ]
    
    def solve(self, board, time_limit=10.0):
        """ä½¿ç”¨å¤šç¨®æ¼”ç®—æ³•æ±‚è§£"""
        
        solutions = []
        start_time = time.time()
        
        for solver in self.solvers:
            if time.time() - start_time > time_limit:
                break
                
            try:
                # ç‚ºæ¯å€‹æ±‚è§£å™¨åˆ†é…æ™‚é–“ç‰‡
                remaining_time = time_limit - (time.time() - start_time)
                solver_time_limit = remaining_time / len(self.solvers)
                
                solver_solutions = solver.solve(board, solver_time_limit)
                solutions.extend(solver_solutions)
                
                # å¦‚æœæ‰¾åˆ°è¶³å¤ çš„è§£ç­”ï¼Œææ—©é€€å‡º
                if len(solutions) >= 5:
                    break
                    
            except Exception as e:
                logger.warning(f"Solver {solver.__class__.__name__} failed: {e}")
                continue
        
        # è©•ä¼°å’Œæ’åºè§£ç­”
        scored_solutions = self.score_solutions(solutions)
        return scored_solutions

class BranchBoundSolver:
    """åˆ†æ”¯é™ç•Œæ±‚è§£å™¨"""
    
    def solve(self, board, time_limit=5.0):
        """ä½¿ç”¨åˆ†æ”¯é™ç•Œæ³•æ±‚è§£"""
        
        start_time = time.time()
        best_solutions = []
        
        # åˆå§‹åŒ–æœå°‹æ¨¹
        initial_state = GameState(board)
        priority_queue = [(0, initial_state)]
        
        while priority_queue and time.time() - start_time < time_limit:
            # å–å¾—æœ€å„ªç¯€é»
            priority, current_state = heapq.heappop(priority_queue)
            
            # æª¢æŸ¥æ˜¯å¦ç‚ºè§£ç­”
            if current_state.is_solved():
                best_solutions.append(current_state.get_solution())
                if len(best_solutions) >= 3:  # é™åˆ¶è§£ç­”æ•¸é‡
                    break
                continue
            
            # ç”Ÿæˆå­ç¯€é»
            for next_state in current_state.generate_next_states():
                # è¨ˆç®—ä¸‹ç•Œ (å•Ÿç™¼å¼å‡½å¼)
                lower_bound = self.calculate_lower_bound(next_state)
                
                # å‰ªææ¢ä»¶
                if lower_bound < float('inf'):
                    heapq.heappush(priority_queue, (lower_bound, next_state))
        
        return best_solutions
    
    def calculate_lower_bound(self, state):
        """è¨ˆç®—ç‹€æ…‹çš„ä¸‹ç•Œä¼°è¨ˆ"""
        # å•Ÿç™¼å¼å‡½å¼ï¼šå‰©é¤˜ç§»å‹•æ¬¡æ•¸çš„æœ€ä½³ä¼°è¨ˆ
        remaining_numbers = state.count_remaining_numbers()
        min_moves_needed = max(0, remaining_numbers - 1)
        return state.moves_count + min_moves_needed
```

## ğŸ”§ ç³»çµ±æœ€ä½³åŒ–ç­–ç•¥

### è¨˜æ†¶é«”ç®¡ç†
```python
class MemoryManager:
    """è¨˜æ†¶é«”ç®¡ç†å™¨"""
    
    def __init__(self):
        self.image_pool = ImagePool(size=50)
        self.prediction_cache = LRUCache(maxsize=1000)
        
    @contextmanager
    def managed_prediction(self):
        """ç®¡ç†é æ¸¬éç¨‹ä¸­çš„è¨˜æ†¶é«”ä½¿ç”¨"""
        try:
            # é æ¸¬å‰æ¸…ç†
            gc.collect()
            tf.keras.backend.clear_session()
            
            yield
            
        finally:
            # é æ¸¬å¾Œæ¸…ç†
            gc.collect()

class ImagePool:
    """åœ–åƒç‰©ä»¶æ± """
    
    def __init__(self, size=50):
        self.pool = [np.zeros((28, 28), dtype=np.uint8) for _ in range(size)]
        self.available = list(self.pool)
        self.lock = threading.Lock()
    
    def get_image(self):
        """å–å¾—å¯ç”¨çš„åœ–åƒç‰©ä»¶"""
        with self.lock:
            if self.available:
                return self.available.pop()
            else:
                # æ± å·²æ»¿ï¼Œå»ºç«‹æ–°ç‰©ä»¶
                return np.zeros((28, 28), dtype=np.uint8)
    
    def return_image(self, img):
        """æ­¸é‚„åœ–åƒç‰©ä»¶åˆ°æ± ä¸­"""
        with self.lock:
            img.fill(0)  # æ¸…é™¤è³‡æ–™
            if len(self.available) < len(self.pool):
                self.available.append(img)
```

### å¤šåŸ·è¡Œç·’æ¶æ§‹
```python
class ConcurrentGameEngine:
    """ä¸¦è¡ŒéŠæˆ²å¼•æ“"""
    
    def __init__(self):
        self.screen_capture_thread = None
        self.prediction_thread = None
        self.solver_thread = None
        
        # åŸ·è¡Œç·’é–“é€šè¨Š
        self.image_queue = queue.Queue(maxsize=10)
        self.prediction_queue = queue.Queue(maxsize=5)
        self.solution_queue = queue.Queue(maxsize=3)
    
    def start_concurrent_processing(self):
        """å•Ÿå‹•ä¸¦è¡Œè™•ç†"""
        
        # è¢å¹•æ“·å–åŸ·è¡Œç·’
        self.screen_capture_thread = threading.Thread(
            target=self.continuous_screen_capture,
            daemon=True
        )
        
        # AI é æ¸¬åŸ·è¡Œç·’
        self.prediction_thread = threading.Thread(
            target=self.continuous_prediction,
            daemon=True
        )
        
        # æ±‚è§£åŸ·è¡Œç·’
        self.solver_thread = threading.Thread(
            target=self.continuous_solving,
            daemon=True
        )
        
        # å•Ÿå‹•æ‰€æœ‰åŸ·è¡Œç·’
        self.screen_capture_thread.start()
        self.prediction_thread.start()
        self.solver_thread.start()
    
    def continuous_screen_capture(self):
        """æŒçºŒè¢å¹•æ“·å–"""
        while not self.shutdown_event.is_set():
            try:
                screenshot = self.capture_screen()
                if not self.image_queue.full():
                    self.image_queue.put(screenshot, timeout=0.1)
            except Exception as e:
                logger.error(f"Screen capture error: {e}")
            
            time.sleep(0.1)  # æ§åˆ¶æ“·å–é »ç‡
```

### å¿«å–ç­–ç•¥
```python
class PredictionCache:
    """é æ¸¬çµæœå¿«å–"""
    
    def __init__(self, maxsize=1000):
        self.cache = {}
        self.access_times = {}
        self.maxsize = maxsize
    
    def get_cache_key(self, image):
        """ç”¢ç”Ÿåœ–åƒçš„å¿«å–éµ"""
        # ä½¿ç”¨åœ–åƒé›œæ¹Šä½œç‚ºéµ
        return hashlib.md5(image.tobytes()).hexdigest()
    
    def get(self, image):
        """å–å¾—å¿«å–çš„é æ¸¬çµæœ"""
        key = self.get_cache_key(image)
        
        if key in self.cache:
            self.access_times[key] = time.time()
            return self.cache[key]
        
        return None
    
    def put(self, image, prediction):
        """å„²å­˜é æ¸¬çµæœåˆ°å¿«å–"""
        key = self.get_cache_key(image)
        
        # æª¢æŸ¥å¿«å–å¤§å°
        if len(self.cache) >= self.maxsize:
            self.evict_lru()
        
        self.cache[key] = prediction
        self.access_times[key] = time.time()
    
    def evict_lru(self):
        """æ¸…é™¤æœ€ä¹…æœªä½¿ç”¨çš„é …ç›®"""
        lru_key = min(self.access_times, key=self.access_times.get)
        del self.cache[lru_key]
        del self.access_times[lru_key]
```

## ğŸ“Š æ•ˆèƒ½ç›£æ§æ¶æ§‹

### ç³»çµ±ç›£æ§
```python
class SystemMonitor:
    """ç³»çµ±æ•ˆèƒ½ç›£æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            'screen_capture_time': [],
            'prediction_time': [],
            'solving_time': [],
            'memory_usage': [],
            'cpu_usage': []
        }
        
        self.monitoring = False
        self.monitor_thread = None
    
    def start_monitoring(self):
        """é–‹å§‹ç›£æ§"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(
            target=self._monitor_loop,
            daemon=True
        )
        self.monitor_thread.start()
    
    def _monitor_loop(self):
        """ç›£æ§å¾ªç’°"""
        while self.monitoring:
            # æ”¶é›†ç³»çµ±æŒ‡æ¨™
            memory_usage = psutil.virtual_memory().percent
            cpu_usage = psutil.cpu_percent()
            
            self.metrics['memory_usage'].append(memory_usage)
            self.metrics['cpu_usage'].append(cpu_usage)
            
            # æª¢æŸ¥ç•°å¸¸æƒ…æ³
            if memory_usage > 90:
                logger.warning(f"High memory usage: {memory_usage}%")
            
            if cpu_usage > 90:
                logger.warning(f"High CPU usage: {cpu_usage}%")
            
            time.sleep(5)  # æ¯ 5 ç§’ç›£æ§ä¸€æ¬¡
    
    @contextmanager
    def measure_time(self, metric_name):
        """æ¸¬é‡æ“ä½œæ™‚é–“"""
        start_time = time.time()
        try:
            yield
        finally:
            duration = time.time() - start_time
            self.metrics[metric_name].append(duration)
    
    def get_performance_summary(self):
        """å–å¾—æ•ˆèƒ½æ‘˜è¦"""
        summary = {}
        
        for metric_name, values in self.metrics.items():
            if values:
                summary[metric_name] = {
                    'avg': np.mean(values),
                    'min': np.min(values),
                    'max': np.max(values),
                    'std': np.std(values),
                    'count': len(values)
                }
        
        return summary
```

é€éé€™å€‹æŠ€è¡“æ¶æ§‹ï¼ŒMake10 å°ˆæ¡ˆå¯¦ç¾äº†é«˜æ•ˆèƒ½ã€å¯æ“´å±•å’Œç©©å®šçš„è‡ªå‹•åŒ–éŠæˆ²æ±‚è§£ç³»çµ±ã€‚
